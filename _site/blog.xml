<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Mike Mahoney</title>
<link>https://mm218.dev/blog.html</link>
<atom:link href="https://mm218.dev/blog.xml" rel="self" type="application/rss+xml"/>
<description>Technology and the Environment</description>
<generator>quarto-1.0.27</generator>
<lastBuildDate>Fri, 18 Feb 2022 05:00:00 GMT</lastBuildDate>
<item>
  <title>Progress, Purpose, Process</title>
  <dc:creator>Mike Mahoney</dc:creator>
  <link>https://mm218.dev/posts/2022-02-18-progress-purpose-process/index.html</link>
  <description><![CDATA[ 




<div class="cell">
<div class="cell-output-display">
<p><img src="https://mm218.dev/posts/2022-02-18-progress-purpose-process/pano.jpg" class="img-fluid" width="3059"></p>
</div>
</div>
<p>Today is my birthday, so please forgive me one of the most self-indulgent things I will ever write.</p>
<p>Two years ago I was living in Boston, working in tech, and a good bit bored. I was recognizing that I had spent most of the past year focusing on goals I had because they were the obvious next step, not because they were building me a life I wanted to live. I had lost a sense of agency over the future.</p>
<p>Luckily, at the time, I had just come across this podcast called “Cortex”. Over the holiday season, the hosts had discussed how they structure their goals around a “yearly theme” – not New Years’ Resolutions, not specific targets that you either achieve or fail at, but a broad concept that they use to inform their decisions over the course of the year. The point is to gently nudge your life in the direction you want it to go. <a href="https://www.youtube.com/watch?v=NVGuFdX5guE">Here’s a video with more information about this</a>; I recommend it.</p>
<p>So I decided that 23 would be my year of Progress; that I’d try and make a habit of making decisions that helped build momentum and kept me moving forward. I quit my job, started a PhD, moved states, and started building the personal and professional networks I rely on today. It wasn’t all perfect – about a month in there was a global pandemic I really wish I could have done something to prevent – but it nudged my life’s trajectory in a direction I’ve been happy with.</p>
<p>So when 24 came and it was time to change my theme, I decided to make it the year of Purpose. The year of Progress had involved saying yes to every opportunity that came my way; with Purpose, I wanted to make sure that I was being intentional with how I spent my time and making explicit decisions about where I’d invest my energy. I’m still not great at it, but I’ve gotten better at saying no when needed. I spent time improving my organization and time management to help me efficiently work through the things I said yes to. And I made a point of learning to consciously decide when to take time off, when to disconnect, and when to purposefully relax, so that I can now make those decisions without worrying about all the things I “should” be doing instead.</p>
<p>Now it’s 25, and it’s time for a new theme. I think my plan is for the year of Process: I like where I am with my life right now, and I like how I spend my time. But I could be better and more careful about how I approach both of those things. I’m going to try to get better with details, to improve my memory around small things.</p>
<p>I told you this would be indulgent. I know this sounds froofy. But it’s worked for me for two years now and I’m betting on round three. And I’m looking forward to seeing where this year takes me.</p>



 ]]></description>
  <guid>https://mm218.dev/posts/2022-02-18-progress-purpose-process/index.html</guid>
  <pubDate>Fri, 18 Feb 2022 05:00:00 GMT</pubDate>
  <media:content url="https://mm218.dev/posts/2022-02-18-progress-purpose-process/pano.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>terrainr: An R package for creating immersive virtual environments</title>
  <dc:creator>Mike Mahoney</dc:creator>
  <link>https://mm218.dev/posts/2022-01-13-terrainr-an-r-package-for-creating-immersive-virtual-environments/index.html</link>
  <description><![CDATA[ 




<p>I’ve got a <a href="https://joss.theoj.org/papers/10.21105/joss.04060">new paper out at the Journal of Open Source Science</a>, documenting the <a href="https://www.mm218.dev/posts/2020/10/">“terrainr” package</a> I’ve been developing since late 2020. JOSS is a fantastic journal and is entirely open-source, so that first link should work for everyone.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://mm218.dev/posts/2022-01-13-terrainr-an-r-package-for-creating-immersive-virtual-environments/fig1.png" class="img-fluid figure-img" width="1571"></p>
<p></p><figcaption class="figure-caption">Left: Where typical geodata-to-IVE workflows leave you. Right: Where terrainr gets you.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The JOSS workflow is absolutely fascinating. I made a <a href="https://github.com/ropensci/terrainr/tree/paper">git branch in the terrainr repo</a> with the files needed to generate the paper, then (through a web form) opened a <a href="https://github.com/openjournals/joss-reviews/issues/4055">pre-review issue on GitHub</a>. The editors used that issue to assign a handling editor, then moved things over to <a href="https://github.com/openjournals/joss-reviews/issues/4060">a review issue</a>, where the paper was processed and prepared for submission via an <a href="https://github.com/openjournals/joss-papers/pull/2885">automatically generated PR</a>. The whole thing was incredibly efficient, and also entirely transparent – the logs of the paper processing workflow will be available until GitHub finally shuts down, a refreshing change compared to standard peer review.</p>
<p>The paper itself is a general overview of the terrainr package, trying to be a new enough contribution that it’s not just repeating the package documentation but not adding enough to spin off into <a href="https://www.mm218.dev/posts/2021-06-14-interactive-landscape-simulations-for-visual-resource-assessment/">an entirely separate research project</a>. It’s also very short – a nice feature of JOSS papers – so rather than summarize here I’ll just suggest you <a href="https://www.mm218.dev/papers/terrainr_2022.pdf">read it yourself</a>.</p>



 ]]></description>
  <guid>https://mm218.dev/posts/2022-01-13-terrainr-an-r-package-for-creating-immersive-virtual-environments/index.html</guid>
  <pubDate>Fri, 14 Jan 2022 05:00:00 GMT</pubDate>
  <media:content url="https://mm218.dev/posts/2022-01-13-terrainr-an-r-package-for-creating-immersive-virtual-environments/fig1.png" medium="image" type="image/png" height="51" width="144"/>
</item>
<item>
  <title>Automated {drat} uploads with GitHub Actions</title>
  <dc:creator>Mike Mahoney</dc:creator>
  <link>https://mm218.dev/posts/2021-09-22-automated-drat-uploads-with-github-actions/index.html</link>
  <description><![CDATA[ 




<p>This is a quick walkthrough of how to use GitHub actions to automatically upload packages to personal <a href="https://github.com/eddelbuettel/drat">{drat}</a> repos.</p>
<p>If you just want the good stuff, <a href="https://github.com/mikemahoney218/upload-to-drat-repo/">here’s the link to the GitHub action I’m using</a> as well as <a href="https://github.com/ropensci/terrainr/blob/main/.github/workflows/drat.yml">the GitHub workflow that uploads terrainr to my own drat repo</a>.</p>
<section id="what-are-we-doing" class="level2">
<h2 class="anchored" data-anchor-id="what-are-we-doing">What are we doing?</h2>
<p><a href="https://github.com/eddelbuettel/drat">{drat}</a> is an R package that helps you set up CRAN-like repositories, hosted (primarily) on GitHub Pages. <a href="https://github.com/features/actions">GitHub Actions</a> is a continuous integration/continuous deployment service<sup>1</sup>, also hosted by GitHub, which lets you trigger compute workloads based on a CRON schedule, activity on a hosted repository, or manually.</p>
<p>This post walks through setting up a GitHub Actions CD workflow<sup>2</sup> to automatically build and upload an R package to a drat repo based on a schedule or repository activity.</p>
</section>
<section id="why-are-we-doing-it" class="level2">
<h2 class="anchored" data-anchor-id="why-are-we-doing-it">Why are we doing it?</h2>
<p>My lab has a number of internal packages we use for our day-to-day work which handle things like downloading data from our central server and producing standardized model assessment outputs. All of these packages live on GitHub in our central organization, and for a long time our workflow for installing these packages has been to clone the repository and then <code>devtools::install</code> the package.</p>
<p>Recently, though, we’ve had to share one of our packages with a number of outside collaborators who we aren’t going to be adding to the organization. We’ve also started working with a number of people who are less familiar with git and GitHub, both externally and within the lab, which means we need to provide a bit more instruction than simply saying “clone the repo and install that”<sup>3</sup>. This also means that solutions like “use <code>remotes::install_github</code> with a PAT” aren’t feasible; we want people to be able to get the packages they need without needing to know anything about GitHub itself. Therefore, we needed a simpler method to actually distribute our code, both to people we’d happily give repo access and people we wouldn’t want to.</p>
<p>For public repositories and organizations, I think the easiest solution to this problem is to set up your own <a href="https://r-universe.dev/organizations/">R Universe</a>, which rOpenSci has written <a href="https://ropensci.org/blog/2021/06/22/setup-runiverse/">fantastic instructions for getting started with</a>; this offloads your responsibility for managing CI to the rOpenSci team. For this project, however, we wanted a separate and mostly hidden repository page, which made {drat} a perfect candidate.</p>
<p>The only problem was how to make sure we were always publishing the newest versions of our package. We’re a small team doing a lot of different things, so being able to automate away any repetitive task (like publishing patch releases to a {drat} repo) can really help reduce the cognitive load and number of mistakes associated with updating our shared codebase.</p>
</section>
<section id="how-did-we-do-it" class="level2">
<h2 class="anchored" data-anchor-id="how-did-we-do-it">How did we do it?</h2>
<p>Because the original version of this workflow is on a private repo, I’ll walk through <a href="https://github.com/ropensci/terrainr/blob/main/.github/workflows/drat.yml">the workflow</a> that uploads <a href="https://github.com/ropensci/terrainr">terrainr</a> to <a href="https://github.com/mikemahoney218/drat">my own personal drat repo</a>. The YAML file that runs the workflow looks like this:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb1-1"><span class="fu" style="color: #4758AB;">on</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb1-2"><span class="at" style="color: #657422;">  </span><span class="fu" style="color: #4758AB;">push</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb1-3"><span class="at" style="color: #657422;">    </span><span class="fu" style="color: #4758AB;">branches</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb1-4"><span class="at" style="color: #657422;">      </span><span class="kw" style="color: #003B4F;">-</span><span class="at" style="color: #657422;"> </span><span class="st" style="color: #20794D;">'main'</span></span>
<span id="cb1-5"><span class="at" style="color: #657422;">    </span><span class="fu" style="color: #4758AB;">paths</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb1-6"><span class="at" style="color: #657422;">      </span><span class="kw" style="color: #003B4F;">-</span><span class="at" style="color: #657422;"> </span><span class="st" style="color: #20794D;">'DESCRIPTION'</span></span>
<span id="cb1-7"><span class="at" style="color: #657422;">  </span><span class="fu" style="color: #4758AB;">workflow_dispatch</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb1-8"></span>
<span id="cb1-9"><span class="fu" style="color: #4758AB;">jobs</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb1-10"><span class="at" style="color: #657422;">  </span><span class="fu" style="color: #4758AB;">drat-upload</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb1-11"><span class="at" style="color: #657422;">    </span><span class="fu" style="color: #4758AB;">runs-on</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> ubuntu-20.04</span></span>
<span id="cb1-12"><span class="at" style="color: #657422;">    </span><span class="fu" style="color: #4758AB;">name</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> Drat Upload</span></span>
<span id="cb1-13"><span class="at" style="color: #657422;">    </span><span class="fu" style="color: #4758AB;">steps</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb1-14"><span class="at" style="color: #657422;">      </span><span class="kw" style="color: #003B4F;">-</span><span class="at" style="color: #657422;"> </span><span class="fu" style="color: #4758AB;">uses</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> mikemahoney218/upload-to-drat-repo@v0.1</span></span>
<span id="cb1-15"><span class="at" style="color: #657422;">        </span><span class="fu" style="color: #4758AB;">with</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb1-16"><span class="at" style="color: #657422;">          </span><span class="fu" style="color: #4758AB;">drat_repo</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> </span><span class="st" style="color: #20794D;">'mikemahoney218/drat'</span></span>
<span id="cb1-17"><span class="at" style="color: #657422;">          </span><span class="fu" style="color: #4758AB;">token</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> </span><span class="st" style="color: #20794D;">"${{ secrets.DRAT_TOKEN }}"</span></span>
<span id="cb1-18"><span class="at" style="color: #657422;">          </span><span class="fu" style="color: #4758AB;">commit_message</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> </span><span class="st" style="color: #20794D;">"Automated update (add terrainr)"</span></span>
<span id="cb1-19"><span class="at" style="color: #657422;">          </span><span class="fu" style="color: #4758AB;">commit_email</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> </span><span class="st" style="color: #20794D;">"mike.mahoney.218@gmail.com"</span></span></code></pre></div>
<p>This script has two main components to it: running the job and configuring the action itself.</p>
<section id="running-the-job" class="level3">
<h3 class="anchored" data-anchor-id="running-the-job">Running the job</h3>
<p>At the top of terrainr’s drat workflow script is the following chunk:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb2-1"><span class="fu" style="color: #4758AB;">on</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb2-2"><span class="at" style="color: #657422;">  </span><span class="fu" style="color: #4758AB;">push</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb2-3"><span class="at" style="color: #657422;">    </span><span class="fu" style="color: #4758AB;">branches</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb2-4"><span class="at" style="color: #657422;">      </span><span class="kw" style="color: #003B4F;">-</span><span class="at" style="color: #657422;"> </span><span class="st" style="color: #20794D;">'main'</span></span>
<span id="cb2-5"><span class="at" style="color: #657422;">    </span><span class="fu" style="color: #4758AB;">paths</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb2-6"><span class="at" style="color: #657422;">      </span><span class="kw" style="color: #003B4F;">-</span><span class="at" style="color: #657422;"> </span><span class="st" style="color: #20794D;">'DESCRIPTION'</span></span>
<span id="cb2-7"><span class="at" style="color: #657422;">  </span><span class="fu" style="color: #4758AB;">workflow_dispatch</span><span class="kw" style="color: #003B4F;">:</span></span></code></pre></div>
<p>This sets up two different ways to trigger the workflow. First off, any <code>push</code> commit to the <code>main</code> branch that touches the <code>DESCRIPTION</code> file will automatically build the package and push it to my drat repo. Because terrainr is published on CRAN and has a handful of users, I do my best to update version numbers whenever I make changes – even during development, I try and bump development versions whenever there’s a fix or update worth mentioning.</p>
<p>Since the version number is stored in <code>DESCRIPTION</code>, this means I’ll only push updated package versions when I’ve actually updated something in the package; my small edits to the CI files, for instance, won’t create a new release.</p>
<p>If you want to be freer about updating your repo, you can drop any of these restrictions. For instance, our internal packages have workflow triggers that look like this:</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb3-1"><span class="fu" style="color: #4758AB;">on</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb3-2"><span class="at" style="color: #657422;">  </span><span class="fu" style="color: #4758AB;">push</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb3-3"><span class="at" style="color: #657422;">    </span><span class="fu" style="color: #4758AB;">branches</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> </span><span class="st" style="color: #20794D;">'main'</span></span></code></pre></div>
<p>In this case, we push an update any time we push <em>any</em> commit to the main branch. This can cause problems – for instance, if we don’t update version numbers then <code>update.packages</code> won’t recognize that local installations are out of date – but makes more sense for our small team and small group of users.</p>
<p>The second method this workflow uses to upload a new version is the <code>workflow_dispatch:</code> option, which lets me manually trigger the workflow from the GitHub UI. This is super helpful in case I accidentally mess up my drat repo, or make a small edit without changing the version number in the <code>DESCRIPTION</code>; without this line I’d have to rebuild the package on my laptop and update the drat repo from my local copy.</p>
<p>There’s a lot of other ways you can set to trigger workflows – <a href="https://docs.github.com/en/actions/learn-github-actions/workflow-syntax-for-github-actions#on">see the full list here</a> – but the other one I want to highlight is that you can also set the workflow to trigger on a schedule using a crontab. This snippet for instance will release daily builds every day at 0:00 UTC:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb4-1"><span class="fu" style="color: #4758AB;">on</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb4-2"><span class="at" style="color: #657422;">  </span><span class="fu" style="color: #4758AB;">schedule</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> </span></span>
<span id="cb4-3"><span class="at" style="color: #657422;">    </span><span class="kw" style="color: #003B4F;">-</span><span class="at" style="color: #657422;"> </span><span class="fu" style="color: #4758AB;">cron</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> </span><span class="st" style="color: #20794D;">'0 0 * * *'</span></span></code></pre></div>
<p>You can use this syntax to create incredibly complex schedules; I personally always use https://crontab.guru/ to make sure my crontabs are right when I’m trying to schedule jobs.</p>
</section>
<section id="configuring-the-action" class="level3">
<h3 class="anchored" data-anchor-id="configuring-the-action">Configuring the action</h3>
<p>The second half of the workflow script actually calls the action to build the package and upload it to your drat repo:</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb5-1"><span class="fu" style="color: #4758AB;">jobs</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb5-2"><span class="at" style="color: #657422;">  </span><span class="fu" style="color: #4758AB;">drat-upload</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb5-3"><span class="at" style="color: #657422;">    </span><span class="fu" style="color: #4758AB;">runs-on</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> ubuntu-20.04</span></span>
<span id="cb5-4"><span class="at" style="color: #657422;">    </span><span class="fu" style="color: #4758AB;">name</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> Drat Upload</span></span>
<span id="cb5-5"><span class="at" style="color: #657422;">    </span><span class="fu" style="color: #4758AB;">steps</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb5-6"><span class="at" style="color: #657422;">      </span><span class="kw" style="color: #003B4F;">-</span><span class="at" style="color: #657422;"> </span><span class="fu" style="color: #4758AB;">uses</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> mikemahoney218/upload-to-drat-repo@v0.1</span></span>
<span id="cb5-7"><span class="at" style="color: #657422;">        </span><span class="fu" style="color: #4758AB;">with</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb5-8"><span class="at" style="color: #657422;">          </span><span class="fu" style="color: #4758AB;">drat_repo</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> </span><span class="st" style="color: #20794D;">'mikemahoney218/drat'</span></span>
<span id="cb5-9"><span class="at" style="color: #657422;">          </span><span class="fu" style="color: #4758AB;">token</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> </span><span class="st" style="color: #20794D;">"${{ secrets.DRAT_TOKEN }}"</span></span>
<span id="cb5-10"><span class="at" style="color: #657422;">          </span><span class="fu" style="color: #4758AB;">commit_message</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> </span><span class="st" style="color: #20794D;">"Automated update (add terrainr)"</span></span>
<span id="cb5-11"><span class="at" style="color: #657422;">          </span><span class="fu" style="color: #4758AB;">commit_email</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> </span><span class="st" style="color: #20794D;">"mike.mahoney.218@gmail.com"</span></span></code></pre></div>
<p>This will, by default, spin up an Ubuntu 20.04 runner and run v0.1 of <a href="https://github.com/mikemahoney218/upload-to-drat-repo/">the upload action</a>, which is the current version. This action will automatically check out the repo the workflow is called from, build and install the R package in that repo, then insert it into a drat repo.</p>
<p>There’s a few input values for this workflow which you <em>must</em> specify, which are under the “with” step:</p>
<ul>
<li><code>drat_repo</code>: The GitHub repository for the drat repo you’re trying to push your package to. If you don’t have a drat repo yet, you can create one locally using <code>drat::initRepo</code>, and then push the created directory up to GitHub.</li>
<li><code>commit_email</code>: The author to write the drat repo commit as; used to set <code>git config user.email</code>. You must provide a value here.</li>
<li><code>token</code>: A <a href="https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token">personal access token (PAT)</a>. The action will use this PAT to clone your package and drat repo, as well as to push your drat repo, so make sure to authorize the PAT to do so. It’s a good idea to use a service account with the fewest permissions possible for this job.</li>
</ul>
<p>You can also customize the job further with a few additional inputs:</p>
<ul>
<li><code>commit_message</code>: The message to use when committing to <code>drat_repo</code>.</li>
<li><code>commit_author</code>: The author to write the commit as; used to set <code>git config user.name</code>.</li>
<li><code>package</code>: The GitHub repository for the package you want to upload. Defaults to the repository the action is running in, but this can be used to run your workflow elsewhere (for instance, if you want to have all your upload jobs scheduled in the drat repo itself).</li>
</ul>
<p>And for most use cases, this should be enough to automatically deploy your package whenever you desire! So far, I’ve tested this workflow on a handful of my own packages (terrainr and then our internal packages), and things are working well so far – if you find any problems or have any suggestions, <a href="https://github.com/mikemahoney218/upload-to-drat-repo/issues">feel free to open an issue on the action repo here.</a></p>


</section>
</section>


<div id="quarto-appendix" class="default"><section class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Kinda. It’s probably more accurate to say GitHub Actions provides hosted compute which is typically used for CI/CD workflows, but can also be applied to other things; I use it to <a href="https://twitter.com/proc_tweets">make art and post to Twitter, for instance.</a>↩︎</p></li>
<li id="fn2"><p>Workflows are explicit, repository-specific jobs, while actions are generic scripts which can be included inside of workflows.↩︎</p></li>
<li id="fn3"><p>I had completely forgotten how complex getting started with GitHub can be as a novice until recently, teaching a Carpentries workshop, I realized that teaching the initial account set-up <a href="https://swcarpentry.github.io/git-novice/07-github/index.html">requires a full 45 minute lesson</a>.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>R</category>
  <category>Tutorials</category>
  <category>CI</category>
  <category>CD</category>
  <category>GitHub Actions</category>
  <guid>https://mm218.dev/posts/2021-09-22-automated-drat-uploads-with-github-actions/index.html</guid>
  <pubDate>Thu, 23 Sep 2021 04:00:00 GMT</pubDate>
</item>
<item>
  <title>Interactive landscape simulations for visual resource assessment</title>
  <dc:creator>Mike Mahoney</dc:creator>
  <link>https://mm218.dev/posts/2021-06-14-interactive-landscape-simulations-for-visual-resource-assessment/index.html</link>
  <description><![CDATA[ 




<p>I’ll be speaking at the <a href="https://sites.google.com/usu.edu/vrsconf03/">2021 Visual Resources Stewardship Conference</a>, presenting a paper (“Interactive landscape simulations for visual resource assessment”, with Colin Beier and Aidan Ackerman) talking about how the use of game engines for spatial visualization can help in visual resource assessment projects.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://mm218.dev/posts/2021-06-14-interactive-landscape-simulations-for-visual-resource-assessment/closer.jpg" class="img-fluid figure-img" width="886"></p>
<p></p><figcaption class="figure-caption">Everything the light touches can see &amp; be seen by the red dot. Users can interactively walk around the landscape to see for themselves if the viewshed algorithm gets things exactly right.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>This was a really fun project, forcing me to push these visualizations in a new direction. The conference itself is in October, and I’ve posted a preprint of the paper <a href="https://www.mm218.dev/papers/vrs_2021.pdf">at this link</a>.</p>
<p>[Update - 2021-06-24] And the code and manuscript used for this paper are now on <a href="https://github.com/mikemahoney218/vrs2021">Github at this link</a>.</p>



 ]]></description>
  <guid>https://mm218.dev/posts/2021-06-14-interactive-landscape-simulations-for-visual-resource-assessment/index.html</guid>
  <pubDate>Mon, 14 Jun 2021 04:00:00 GMT</pubDate>
  <media:content url="https://mm218.dev/posts/2021-06-14-interactive-landscape-simulations-for-visual-resource-assessment/closer.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Virtual environments talk at useR! 2021</title>
  <dc:creator>Mike Mahoney</dc:creator>
  <link>https://mm218.dev/posts/2021-06-12-virtual-environments-talk-at-user-2021/index.html</link>
  <description><![CDATA[ 




<p>I’m thrilled to be giving a talk (with Colin Beier and Aidan Ackerman) at useR 2021! We’re calling the talk “Virtual Environments: Using R as a Frontend for 3D Rendering of Digital Landscapes” – generally speaking, I’m talking about the idea of using R to create visualizations inside game engines, and specifically about how we do so using terrainr.</p>
<p>The video should go up on YouTube after the conference, and the slides (and a rough script for the talk) are online at https://github.com/mikemahoney218/user2021 . My favorite line from the script is “R is where our users are” – I didn’t quite realize I had any Boston accent left until I tripped over that sentence a few times.</p>



 ]]></description>
  <guid>https://mm218.dev/posts/2021-06-12-virtual-environments-talk-at-user-2021/index.html</guid>
  <pubDate>Sat, 12 Jun 2021 04:00:00 GMT</pubDate>
</item>
<item>
  <title>What’s new in terrainr 0.4.0?</title>
  <dc:creator>Mike Mahoney</dc:creator>
  <link>https://mm218.dev/posts/2021-04-22-terrainr-version-040-is-now-on-cran/index.html</link>
  <description><![CDATA[ 




<p>terrainr version 0.4.0 is now on CRAN! This version is a relatively minor update that shouldn’t impact most workflows, but makes some changes to improve the logic and consistency of the package. The rest of this post runs through the changes you can expect if you <code>update.packages()</code> any time soon!</p>
<section id="whats-a-terrainr" class="level2">
<h2 class="anchored" data-anchor-id="whats-a-terrainr">What’s a terrainr?</h2>
<p><a href="https://docs.ropensci.org/terrainr/">terrainr</a> is an R package for the retrieval and visualization of spatial data. It provides functions to download elevation data and basemap tiles for points within the United States (using public domain data from the USGS National Map), visualize them in R via ggplot2, and process them for 3D visualization using the Unity 3D engine. You can see <a href="https://docs.ropensci.org/terrainr/">the GitHub repo here!</a></p>
</section>
<section id="merge_rasters-can-handle-tiles-with-different-numbers-of-bands" class="level2">
<h2 class="anchored" data-anchor-id="merge_rasters-can-handle-tiles-with-different-numbers-of-bands"><code>merge_rasters</code> can handle tiles with different numbers of bands</h2>
<p>The old implementation of <code>merge_rasters</code> was very bulky, read all your map tiles into memory at once, and was a bit of a mess to maintain thanks to the large number of paths you could theoretically take through the code. The commit (suggested via rOpenSci review!) replacing it with <code>gdalwarp</code> via <code>sf</code> is probably the single best code improvement I’ve made to this repo. Unfortunately, the old method could also handle merging rasters with differing numbers of bands, while the simple <code>gdalwarp</code> fix couldn’t.</p>
<p>So the old implementation is back as an internal method while I look for a better solution to this problem. <code>merge_rasters</code> will now attempt to use <code>gdalwarp</code> to merge your input files and then fall back to (a massively simplified version of) the older version if <code>gdalwarp</code> fails.</p>
<p>As for why you’d want to automatically merge rasters with different numbers of bands, well…</p>
</section>
<section id="get_tiles-doesnt-auto-download-transparency-values-for-naip" class="level2">
<h2 class="anchored" data-anchor-id="get_tiles-doesnt-auto-download-transparency-values-for-naip"><code>get_tiles</code> doesn’t auto-download transparency values for NAIP</h2>
<p>NAIP orthophotography provides fantastic continuous 1-meter images for the continental United States. When downloading these photos with the argument <code>transparency = true</code>, which used to be the default, <em>most</em> photos don’t have any transparent pixels to talk about and as such are returned and saved as 3 band rasters (RGB images). <em>Some</em> photos, however, do have such pixels and are returned with a 4th alpha band. This causes problems with <code>gdalwarp</code> as well as image editing software, and the majority of the time users are not better served by these pixels being transparent.</p>
<p>As a result, this version changes the default <code>transparency</code> argument for <code>get_tiles</code> and <code>hit_national_map_api</code> to <code>false</code> when downloading NAIP images (no other data source is impacted). This is one of the reasons this version gets a 0.x.0 number – while it should be a small change, the same inputs to functions no longer returns the same outputs (though I doubt people would notice), so I’m counting this as a breaking change.</p>
<p>There’s a slightly more impactful breaking change worth noting though:</p>
</section>
<section id="functions-pay-attention-to-the-provided-crs" class="level2">
<h2 class="anchored" data-anchor-id="functions-pay-attention-to-the-provided-crs">Functions pay attention to the provided CRS</h2>
<p>This header is actually about two distinct changes.</p>
<p>First, another new behavior with <code>get_tiles</code> is that rather than assuming the provided data and downloaded image should both be using the WGS84 CRS (EPSG 4326), <code>get_tiles</code> will now infer the EPSG CRS from any provided <code>sf</code> or <code>Raster</code> object. If the numeric code is missing, this function will still assume 4326.</p>
<p>Similarly, rather than specifying <code>target_crs</code> in <code>vector_to_overlay</code>, this function will now return an overlay projected to match <code>reference_raster</code>’s CRS. Missing CRS are handled slightly differently here – if the <code>error_crs</code> argument is <code>NULL</code>, this function will warn; if <code>FALSE</code> it will assume 4326, and if <code>TRUE</code> it will interrupt the function with an error.</p>
<p>Those are the major changes to this iteration! On top of these there are some minor changes to the package internals, slowly removing dead code paths and simplifying things behind the scenes. If you have any problems (bugs or missing features) with the package, feel free to <a href="https://github.com/ropensci/terrainr/issues">open an issue!</a></p>


</section>

 ]]></description>
  <guid>https://mm218.dev/posts/2021-04-22-terrainr-version-040-is-now-on-cran/index.html</guid>
  <pubDate>Thu, 22 Apr 2021 04:00:00 GMT</pubDate>
</item>
<item>
  <title>terrainr 0.3.0 is out today</title>
  <dc:creator>Mike Mahoney</dc:creator>
  <link>https://mm218.dev/posts/2021/02/terrainr/index.html</link>
  <description><![CDATA[ 




<p><a href="https://mikemahoney218.github.io/terrainr/">terrainr</a> is <a href="https://github.com/ropensci/software-review/issues/416">in review with rOpenSci</a> and the first review just came back! I’ve been working through the comments over the past week or so, and today that work has culminated in the release of terrainr version 0.3.0.</p>
<p>This is a big release with a handful of breaking changes, so I felt like I should give a brief overview of the biggest user-facing changes.</p>
<section id="breaking-changes" class="level2">
<h2 class="anchored" data-anchor-id="breaking-changes">Breaking Changes</h2>
<section id="object-classes-are-dead-long-live-object-classes" class="level3">
<h3 class="anchored" data-anchor-id="object-classes-are-dead-long-live-object-classes">Object Classes Are Dead; Long Live Object Classes</h3>
<p>The single largest change is that <em>terrainr specific classes are no longer exported</em>, and users shouldn’t need to worry about getting data into or out of those formats anymore. Instead, use any <code>sf</code> or <code>Raster</code> object in their place. For instance, workflows that used to look like this:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="co" style="color: #5E5E5E;"># Doesn't run:</span></span>
<span id="cb1-2"><span class="fu" style="color: #4758AB;">library</span>(terrainr)</span>
<span id="cb1-3">simulated_data <span class="ot" style="color: #003B4F;">&lt;-</span>  <span class="fu" style="color: #4758AB;">data.frame</span>(<span class="at" style="color: #657422;">id =</span> <span class="fu" style="color: #4758AB;">seq</span>(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">100</span>, <span class="dv" style="color: #AD0000;">1</span>),</span>
<span id="cb1-4">                              <span class="at" style="color: #657422;">lat =</span> <span class="fu" style="color: #4758AB;">runif</span>(<span class="dv" style="color: #AD0000;">100</span>, <span class="fl" style="color: #AD0000;">44.04905</span>, <span class="fl" style="color: #AD0000;">44.17609</span>), </span>
<span id="cb1-5">                              <span class="at" style="color: #657422;">lng =</span> <span class="fu" style="color: #4758AB;">runif</span>(<span class="dv" style="color: #AD0000;">100</span>, <span class="sc" style="color: #5E5E5E;">-</span><span class="fl" style="color: #AD0000;">74.01188</span>, <span class="sc" style="color: #5E5E5E;">-</span><span class="fl" style="color: #AD0000;">73.83493</span>))</span>
<span id="cb1-6"></span>
<span id="cb1-7">bbox <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">get_bbox</span>(<span class="at" style="color: #657422;">lat =</span> simulated_data<span class="sc" style="color: #5E5E5E;">$</span>lat, <span class="at" style="color: #657422;">lng =</span> simulated_data<span class="sc" style="color: #5E5E5E;">$</span>lng) </span>
<span id="cb1-8"></span>
<span id="cb1-9">output_tiles <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">get_tiles</span>(<span class="at" style="color: #657422;">bbox =</span> bbox,</span>
<span id="cb1-10">                          <span class="at" style="color: #657422;">services =</span> <span class="fu" style="color: #4758AB;">c</span>(<span class="st" style="color: #20794D;">"elevation"</span>, <span class="st" style="color: #20794D;">"ortho"</span>),</span>
<span id="cb1-11">                          <span class="at" style="color: #657422;">resolution =</span> <span class="dv" style="color: #AD0000;">90</span>)</span></code></pre></div>
</div>
<p>Now look like this:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><span class="fu" style="color: #4758AB;">library</span>(terrainr)</span>
<span id="cb2-2">simulated_data <span class="ot" style="color: #003B4F;">&lt;-</span>  <span class="fu" style="color: #4758AB;">data.frame</span>(<span class="at" style="color: #657422;">id =</span> <span class="fu" style="color: #4758AB;">seq</span>(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">100</span>, <span class="dv" style="color: #AD0000;">1</span>),</span>
<span id="cb2-3">                              <span class="at" style="color: #657422;">lat =</span> <span class="fu" style="color: #4758AB;">runif</span>(<span class="dv" style="color: #AD0000;">100</span>, <span class="fl" style="color: #AD0000;">44.04905</span>, <span class="fl" style="color: #AD0000;">44.17609</span>), </span>
<span id="cb2-4">                              <span class="at" style="color: #657422;">lng =</span> <span class="fu" style="color: #4758AB;">runif</span>(<span class="dv" style="color: #AD0000;">100</span>, <span class="sc" style="color: #5E5E5E;">-</span><span class="fl" style="color: #AD0000;">74.01188</span>, <span class="sc" style="color: #5E5E5E;">-</span><span class="fl" style="color: #AD0000;">73.83493</span>))</span>
<span id="cb2-5"></span>
<span id="cb2-6">simulated_data <span class="ot" style="color: #003B4F;">&lt;-</span> sf<span class="sc" style="color: #5E5E5E;">::</span><span class="fu" style="color: #4758AB;">st_as_sf</span>(simulated_data, <span class="at" style="color: #657422;">coords =</span> <span class="fu" style="color: #4758AB;">c</span>(<span class="st" style="color: #20794D;">"lng"</span>, <span class="st" style="color: #20794D;">"lat"</span>))</span>
<span id="cb2-7">simulated_data <span class="ot" style="color: #003B4F;">&lt;-</span> sf<span class="sc" style="color: #5E5E5E;">::</span><span class="fu" style="color: #4758AB;">st_set_crs</span>(simulated_data, <span class="dv" style="color: #AD0000;">4326</span>)</span>
<span id="cb2-8"></span>
<span id="cb2-9">output_tiles <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">get_tiles</span>(<span class="at" style="color: #657422;">data =</span> simulated_data,</span>
<span id="cb2-10">                          <span class="at" style="color: #657422;">services =</span> <span class="fu" style="color: #4758AB;">c</span>(<span class="st" style="color: #20794D;">"elevation"</span>, <span class="st" style="color: #20794D;">"ortho"</span>),</span>
<span id="cb2-11">                          <span class="at" style="color: #657422;">resolution =</span> <span class="dv" style="color: #AD0000;">90</span>)</span></code></pre></div>
</div>
<p>As part of this change, <code>get_bbox</code>, <code>get_coordinate_bbox</code>, and all class creation and export functions are gone now. Use sf (or Raster*) objects in their place instead.</p>
</section>
<section id="new-names-who-this" class="level3">
<h3 class="anchored" data-anchor-id="new-names-who-this">New Names, Who This?</h3>
<p><code>get_tiles</code> now uses the <code>services</code> argument to name its output list:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><span class="fu" style="color: #4758AB;">names</span>(output_tiles)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "elevation" "ortho"    </code></pre>
</div>
</div>
<p>This means that if you request the service <code>elevation</code> you can retrieve your tiles using the name <code>elevation</code>. If you request the same endpoint with multiple names, <code>get_tiles</code> will use whatever name was first in the vector.</p>
</section>
<section id="fewer-utilities-more-useful" class="level3">
<h3 class="anchored" data-anchor-id="fewer-utilities-more-useful">Fewer Utilities, More Useful</h3>
<p>Utility functions <code>calc_haversine_distance</code>, <code>convert_distance</code>, <code>point_from_distance</code>, <code>rad_to_deg</code>, and <code>deg_to_rad</code> have been removed (or removed from exports). For unit conversions, check out the <a href="cran.r-project.org/package=units">units</a> package. This shouldn’t impact the main uses of the package, but is still worth flagging.</p>
</section>
</section>
<section id="show-me-what-you-got" class="level2">
<h2 class="anchored" data-anchor-id="show-me-what-you-got">Show Me What You Got</h2>
<p>terrainr 0.3.0 adds a ggplot2 geom, <code>geom_spatial_rgb</code>, for plotting 3 band RGB rasters:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><span class="fu" style="color: #4758AB;">library</span>(ggplot2)</span>
<span id="cb5-2"></span>
<span id="cb5-3"><span class="fu" style="color: #4758AB;">ggplot</span>() <span class="sc" style="color: #5E5E5E;">+</span> </span>
<span id="cb5-4">  <span class="fu" style="color: #4758AB;">geom_spatial_rgb</span>(<span class="at" style="color: #657422;">data =</span> output_tiles[[<span class="st" style="color: #20794D;">"ortho"</span>]],</span>
<span id="cb5-5">                   <span class="co" style="color: #5E5E5E;"># Required aesthetics r/g/b specify color bands:</span></span>
<span id="cb5-6">                   <span class="fu" style="color: #4758AB;">aes</span>(<span class="at" style="color: #657422;">x =</span> x, <span class="at" style="color: #657422;">y =</span> y, <span class="at" style="color: #657422;">r =</span> red, <span class="at" style="color: #657422;">g =</span> green, <span class="at" style="color: #657422;">b =</span> blue)) <span class="sc" style="color: #5E5E5E;">+</span> </span>
<span id="cb5-7">  <span class="fu" style="color: #4758AB;">coord_sf</span>(<span class="at" style="color: #657422;">crs =</span> <span class="dv" style="color: #AD0000;">4326</span>)</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://mm218.dev/posts/2021/02/terrainr/index_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Note that above we just passed the file path to our raster; we can also pass a RasterStack:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1">ortho <span class="ot" style="color: #003B4F;">&lt;-</span> raster<span class="sc" style="color: #5E5E5E;">::</span><span class="fu" style="color: #4758AB;">stack</span>(output_tiles[[<span class="st" style="color: #20794D;">"ortho"</span>]])</span>
<span id="cb6-2"></span>
<span id="cb6-3"><span class="fu" style="color: #4758AB;">ggplot</span>() <span class="sc" style="color: #5E5E5E;">+</span> </span>
<span id="cb6-4">  <span class="fu" style="color: #4758AB;">geom_spatial_rgb</span>(<span class="at" style="color: #657422;">data =</span> ortho,</span>
<span id="cb6-5">                   <span class="fu" style="color: #4758AB;">aes</span>(<span class="at" style="color: #657422;">x =</span> x, <span class="at" style="color: #657422;">y =</span> y, <span class="at" style="color: #657422;">r =</span> red, <span class="at" style="color: #657422;">g =</span> green, <span class="at" style="color: #657422;">b =</span> blue)) <span class="sc" style="color: #5E5E5E;">+</span> </span>
<span id="cb6-6">  <span class="fu" style="color: #4758AB;">coord_sf</span>(<span class="at" style="color: #657422;">crs =</span> <span class="dv" style="color: #AD0000;">4326</span>)</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://mm218.dev/posts/2021/02/terrainr/index_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Or a data.frame:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1">ortho_df <span class="ot" style="color: #003B4F;">&lt;-</span> raster<span class="sc" style="color: #5E5E5E;">::</span><span class="fu" style="color: #4758AB;">as.data.frame</span>(ortho, <span class="at" style="color: #657422;">xy =</span> <span class="cn" style="color: #8f5902;">TRUE</span>)</span>
<span id="cb7-2"><span class="fu" style="color: #4758AB;">names</span>(ortho_df) <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">c</span>(<span class="st" style="color: #20794D;">"x"</span>, <span class="st" style="color: #20794D;">"y"</span>, <span class="st" style="color: #20794D;">"red"</span>, <span class="st" style="color: #20794D;">"green"</span>, <span class="st" style="color: #20794D;">"blue"</span>)</span>
<span id="cb7-3"></span>
<span id="cb7-4"><span class="fu" style="color: #4758AB;">ggplot</span>() <span class="sc" style="color: #5E5E5E;">+</span> </span>
<span id="cb7-5">  <span class="fu" style="color: #4758AB;">geom_spatial_rgb</span>(<span class="at" style="color: #657422;">data =</span> ortho,</span>
<span id="cb7-6">                   <span class="fu" style="color: #4758AB;">aes</span>(<span class="at" style="color: #657422;">x =</span> x, <span class="at" style="color: #657422;">y =</span> y, <span class="at" style="color: #657422;">r =</span> red, <span class="at" style="color: #657422;">g =</span> green, <span class="at" style="color: #657422;">b =</span> blue)) <span class="sc" style="color: #5E5E5E;">+</span> </span>
<span id="cb7-7">  <span class="fu" style="color: #4758AB;">coord_sf</span>(<span class="at" style="color: #657422;">crs =</span> <span class="dv" style="color: #AD0000;">4326</span>)</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://mm218.dev/posts/2021/02/terrainr/index_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Note that each step here gives you a little more control over the output image – for instance, if your raster bands aren’t in RGB order (or you have more than RGBA bands), you’ll need to provide a data.frame to get a true color image.</p>
<p>You can then use these basemaps like most other ggplot geoms:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><span class="fu" style="color: #4758AB;">ggplot</span>() <span class="sc" style="color: #5E5E5E;">+</span> </span>
<span id="cb8-2">  <span class="fu" style="color: #4758AB;">geom_spatial_rgb</span>(<span class="at" style="color: #657422;">data =</span> ortho_df,</span>
<span id="cb8-3">                   <span class="fu" style="color: #4758AB;">aes</span>(<span class="at" style="color: #657422;">x =</span> x, <span class="at" style="color: #657422;">y =</span> y, <span class="at" style="color: #657422;">r =</span> red, <span class="at" style="color: #657422;">g =</span> green, <span class="at" style="color: #657422;">b =</span> blue)) <span class="sc" style="color: #5E5E5E;">+</span> </span>
<span id="cb8-4">  <span class="fu" style="color: #4758AB;">geom_sf</span>(<span class="at" style="color: #657422;">data =</span> simulated_data) <span class="sc" style="color: #5E5E5E;">+</span> </span>
<span id="cb8-5">  <span class="fu" style="color: #4758AB;">coord_sf</span>(<span class="at" style="color: #657422;">crs =</span> <span class="dv" style="color: #AD0000;">4326</span>)</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://mm218.dev/posts/2021/02/terrainr/index_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="new-docs-who-this" class="level2">
<h2 class="anchored" data-anchor-id="new-docs-who-this">New Docs, Who This?</h2>
<p>Those are just a few of the changes in 0.3.0; you can find a longer list in the NEWS file.</p>
<p>One thing not mentioned in the <a href="https://mikemahoney218.github.io/terrainr/news/index.html">NEWS</a> file, though, is that this version of terrainr included a complete rewrite of the documentation. The docs were mostly written while the package was being conceptually developed, and as a result gave a bit too much emphasis to some ideas while completely ignoring others. So I’ve rewritten all of the documentation that lives on the <a href="https://mikemahoney218.github.io/terrainr/">terrainr website</a> – let me know what you think about the new versions (or if you catch anything I’ve missed!).</p>


</section>

 ]]></description>
  <category>R</category>
  <category>Data science</category>
  <category>terrainr</category>
  <guid>https://mm218.dev/posts/2021/02/terrainr/index.html</guid>
  <pubDate>Wed, 17 Feb 2021 05:00:00 GMT</pubDate>
</item>
<item>
  <title>Model averaging methods: how and why to build ensemble models</title>
  <dc:creator>Mike Mahoney</dc:creator>
  <link>https://mm218.dev/posts/2021/01/model-averaging/index.html</link>
  <description><![CDATA[ 




<div class="cell">
<div class="cell-output-display">
<p><img src="https://mm218.dev/posts/2021/01/model-averaging/model_avg.jpg" class="img-fluid" width="3612"></p>
</div>
</div>
<aside>
Cartoon components are CC-BY 4.0 Allison Horst (<a href="https://twitter.com/allison_horst/">allison_horst on twitter</a>)
</aside>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Building models is hard. Choosing what models to build can be even harder. With seemingly infinite different modeling approaches to select between (and somehow even more individual implementations), it can be difficult to guess what methods will be the best fit for your data – particularly if you’re working with data that will change over time with new observations or predictors being added to the mix.</p>
<p>Usually, we disclose this sort of uncertainty with things like confidence intervals and standard errors. Yet when it comes to selecting a single model, we often don’t discuss how confident we are in that model being the <em>right</em> one – instead, we present and report only our final choice as if there was no chance other candidate models would be as good or even better fits.</p>
<p>Ensemble models prove a way to deal with that uncertainty <span class="citation" data-cites="Wintle">(Wintle et al. 2003)</span>. By averaging predictions from a handful of candidate models, ensembles acknowledge that there might be multiple models that could be used to describe our data – and by weighting the average we can communicate how confident we are in each individual model’s view of the world. Of course, while <a href="https://www.bloomberg.com/graphics/2015-paul-ford-what-is-code/">this is all nice and flowery, it needs to work too</a> – and model averaging delivers, typically reducing prediction errors beyond even above even the best individual component model <span class="citation" data-cites="Dormann">(Dormann et al. 2018)</span>.</p>
<p>There are a ton of approaches to model averaging<sup>1</sup>. The rest of this post will walk through a few of the simplest – equal-weight averaging, fit-based averages, and model-based combinations – that you can easily implement yourself without needing to worry about slowing down your iteration time or making your modeling code too complex.</p>
<section id="getting-started" class="level3">
<h3 class="anchored" data-anchor-id="getting-started">Getting Started</h3>
<p>We’ll be using the following libraries for data manipulation and visualization:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="fu" style="color: #4758AB;">library</span>(dplyr)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'dplyr'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following objects are masked from 'package:stats':

    filter, lag</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following objects are masked from 'package:base':

    intersect, setdiff, setequal, union</code></pre>
</div>
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><span class="fu" style="color: #4758AB;">library</span>(tidyr)</span>
<span id="cb5-2"><span class="fu" style="color: #4758AB;">library</span>(ggplot2)</span>
<span id="cb5-3"><span class="fu" style="color: #4758AB;">library</span>(knitr)</span></code></pre></div>
</div>
<p>Additionally, we’ll be using both <code>ranger</code> and <code>lightgbm</code> to develop component models:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><span class="fu" style="color: #4758AB;">library</span>(ranger)</span>
<span id="cb6-2"><span class="fu" style="color: #4758AB;">library</span>(lightgbm)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'lightgbm'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following object is masked from 'package:dplyr':

    slice</code></pre>
</div>
</div>
<p>And finally, we need the actual data we’re modeling. For this example, we’ll build models predicting the arrival delay of the flights included in the <code>nycflights13</code> package using both flight details and weather data. This next chunk of code will preprocess our data into a model-ready format:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1">flights <span class="ot" style="color: #003B4F;">&lt;-</span> nycflights13<span class="sc" style="color: #5E5E5E;">::</span>flights</span>
<span id="cb9-2">weather <span class="ot" style="color: #003B4F;">&lt;-</span> nycflights13<span class="sc" style="color: #5E5E5E;">::</span>weather <span class="sc" style="color: #5E5E5E;">%&gt;%</span> </span>
<span id="cb9-3">  <span class="fu" style="color: #4758AB;">select</span>(<span class="sc" style="color: #5E5E5E;">-</span>wind_gust) <span class="co" style="color: #5E5E5E;"># About 80% missing values, so we'll drop this column</span></span>
<span id="cb9-4"></span>
<span id="cb9-5"><span class="co" style="color: #5E5E5E;"># combine the two data frames into one complete set</span></span>
<span id="cb9-6">flight_data <span class="ot" style="color: #003B4F;">&lt;-</span> flights <span class="sc" style="color: #5E5E5E;">%&gt;%</span> </span>
<span id="cb9-7">  <span class="fu" style="color: #4758AB;">left_join</span>(weather,</span>
<span id="cb9-8">            <span class="at" style="color: #657422;">by =</span> <span class="fu" style="color: #4758AB;">c</span>(<span class="st" style="color: #20794D;">"year"</span>, <span class="st" style="color: #20794D;">"month"</span>, <span class="st" style="color: #20794D;">"day"</span>, <span class="st" style="color: #20794D;">"origin"</span>, <span class="st" style="color: #20794D;">"hour"</span>, <span class="st" style="color: #20794D;">"time_hour"</span>)) <span class="sc" style="color: #5E5E5E;">%&gt;%</span> </span>
<span id="cb9-9">  <span class="fu" style="color: #4758AB;">drop_na</span>()</span>
<span id="cb9-10"></span>
<span id="cb9-11">flight_data <span class="ot" style="color: #003B4F;">&lt;-</span> flight_data <span class="sc" style="color: #5E5E5E;">%&gt;%</span> </span>
<span id="cb9-12">  <span class="co" style="color: #5E5E5E;"># Drop 37 pretty dramatic outliers</span></span>
<span id="cb9-13">  <span class="fu" style="color: #4758AB;">filter</span>(arr_delay <span class="sc" style="color: #5E5E5E;">&lt;=</span> <span class="dv" style="color: #AD0000;">500</span>) <span class="sc" style="color: #5E5E5E;">%&gt;%</span> </span>
<span id="cb9-14">  <span class="co" style="color: #5E5E5E;"># Get rid of useless predictors -- </span></span>
<span id="cb9-15">  <span class="co" style="color: #5E5E5E;"># these each cause problems with at least one of our regressions</span></span>
<span id="cb9-16">  <span class="fu" style="color: #4758AB;">select</span>(<span class="sc" style="color: #5E5E5E;">-</span>year, <span class="sc" style="color: #5E5E5E;">-</span>time_hour, <span class="sc" style="color: #5E5E5E;">-</span>minute) <span class="sc" style="color: #5E5E5E;">%&gt;%</span> </span>
<span id="cb9-17">  <span class="co" style="color: #5E5E5E;"># Skip the work of encoding non-numeric values, to save my poor laptop</span></span>
<span id="cb9-18">  <span class="fu" style="color: #4758AB;">select_if</span>(is.numeric)</span></code></pre></div>
</div>
<p>And for one final pre-processing step, we’ll split our data into training, validation, and testing sets (sticking 20% into both validation and testing and dumping the rest into training). We’ll be using model performance against the validation set to determine weights for our averages.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><span class="fu" style="color: #4758AB;">set.seed</span>(<span class="dv" style="color: #AD0000;">123</span>)</span>
<span id="cb10-2"><span class="co" style="color: #5E5E5E;"># Generate a random sequence to subset our data into train/validate/test splits</span></span>
<span id="cb10-3">row_index <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">sample</span>(<span class="fu" style="color: #4758AB;">nrow</span>(flight_data), <span class="fu" style="color: #4758AB;">nrow</span>(flight_data))</span>
<span id="cb10-4"></span>
<span id="cb10-5"><span class="co" style="color: #5E5E5E;"># Testing gets the 20% of data with the highest random index values</span></span>
<span id="cb10-6">flight_testing <span class="ot" style="color: #003B4F;">&lt;-</span> flight_data[row_index <span class="sc" style="color: #5E5E5E;">&gt;=</span> <span class="fu" style="color: #4758AB;">nrow</span>(flight_data) <span class="sc" style="color: #5E5E5E;">*</span> <span class="fl" style="color: #AD0000;">0.8</span>, ]</span>
<span id="cb10-7"></span>
<span id="cb10-8"><span class="co" style="color: #5E5E5E;"># Validation gets the next highest 20%</span></span>
<span id="cb10-9">flight_validation <span class="ot" style="color: #003B4F;">&lt;-</span> flight_data[row_index <span class="sc" style="color: #5E5E5E;">&gt;=</span> <span class="fu" style="color: #4758AB;">nrow</span>(flight_data) <span class="sc" style="color: #5E5E5E;">*</span> <span class="fl" style="color: #AD0000;">0.6</span> <span class="sc" style="color: #5E5E5E;">&amp;</span></span>
<span id="cb10-10">                                   row_index <span class="sc" style="color: #5E5E5E;">&lt;</span> <span class="fu" style="color: #4758AB;">nrow</span>(flight_data) <span class="sc" style="color: #5E5E5E;">*</span> <span class="fl" style="color: #AD0000;">0.8</span>, ]</span>
<span id="cb10-11"></span>
<span id="cb10-12"><span class="co" style="color: #5E5E5E;"># Training gets the rest</span></span>
<span id="cb10-13">flight_training <span class="ot" style="color: #003B4F;">&lt;-</span> flight_data[row_index <span class="sc" style="color: #5E5E5E;">&lt;</span> <span class="fu" style="color: #4758AB;">nrow</span>(flight_data) <span class="sc" style="color: #5E5E5E;">*</span> <span class="fl" style="color: #AD0000;">0.6</span>, ]</span>
<span id="cb10-14"></span>
<span id="cb10-15"><span class="co" style="color: #5E5E5E;"># LightGBM requires matrices, rather than data frames and formulas:</span></span>
<span id="cb10-16">xtrain <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">as.matrix</span>(<span class="fu" style="color: #4758AB;">select</span>(flight_training, <span class="sc" style="color: #5E5E5E;">-</span>arr_delay))</span>
<span id="cb10-17">ytrain <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">as.matrix</span>(flight_training[[<span class="st" style="color: #20794D;">"arr_delay"</span>]])</span>
<span id="cb10-18"></span>
<span id="cb10-19">xvalid <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">as.matrix</span>(<span class="fu" style="color: #4758AB;">select</span>(flight_validation, <span class="sc" style="color: #5E5E5E;">-</span>arr_delay))</span>
<span id="cb10-20">xtest <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">as.matrix</span>(<span class="fu" style="color: #4758AB;">select</span>(flight_testing, <span class="sc" style="color: #5E5E5E;">-</span>arr_delay))</span></code></pre></div>
</div>
<p>So with that out of the way, it’s time to start training our models!</p>
</section>
</section>
<section id="component-models" class="level2">
<h2 class="anchored" data-anchor-id="component-models">Component Models</h2>
<section id="linear-model" class="level3">
<h3 class="anchored" data-anchor-id="linear-model">Linear Model</h3>
<p>Let’s start off with a simple linear regression model, using all of our predictors in the flight dataset to try and estimate arrival delays:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1">linear_model <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">lm</span>(arr_delay <span class="sc" style="color: #5E5E5E;">~</span> ., flight_training)</span>
<span id="cb11-2"><span class="fu" style="color: #4758AB;">summary</span>(linear_model)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = arr_delay ~ ., data = flight_training)

Residuals:
    Min      1Q  Median      3Q     Max 
-58.895  -9.133  -1.538   7.076 159.388 

Coefficients:
                  Estimate  Std. Error  t value           Pr(&gt;|t|)    
(Intercept)    -4.61324673  5.99244467   -0.770           0.441394    
month           0.03825040  0.01117238    3.424           0.000618 ***
day             0.02220492  0.00410860    5.404 0.0000000650770797 ***
dep_time        0.00009509  0.00027953    0.340           0.733722    
sched_dep_time -0.00349249  0.00189448   -1.844           0.065257 .  
dep_delay       1.01251264  0.00106768  948.332            &lt; 2e-16 ***
arr_time        0.00088164  0.00011818    7.460 0.0000000000000868 ***
sched_arr_time -0.00471343  0.00014783  -31.884            &lt; 2e-16 ***
flight         -0.00004692  0.00002541   -1.846           0.064863 .  
air_time        0.75629859  0.00307431  246.006            &lt; 2e-16 ***
distance       -0.09791613  0.00039245 -249.500            &lt; 2e-16 ***
hour            0.59997173  0.18707035    3.207           0.001341 ** 
temp            0.11726625  0.02231781    5.254 0.0000001487014873 ***
dewp            0.03632142  0.02404661    1.510           0.130928    
humid           0.01860018  0.01228626    1.514           0.130053    
wind_dir       -0.00607627  0.00040085  -15.158            &lt; 2e-16 ***
wind_speed      0.19198999  0.00753768   25.471            &lt; 2e-16 ***
precip         26.88470146  3.01386317    8.920            &lt; 2e-16 ***
pressure       -0.01634187  0.00561852   -2.909           0.003631 ** 
visib          -0.46031686  0.03238825  -14.212            &lt; 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 14.82 on 170687 degrees of freedom
Multiple R-squared:  0.8707,    Adjusted R-squared:  0.8707 
F-statistic: 6.048e+04 on 19 and 170687 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>Cool! We have our first model – and it seems to be a pretty ok fit, with an R^2 of 0.87. We could probably make this model better by being a bit more selective with our terms or throwing in some interaction terms – but as a first stab at a model that we’ll incorporate into our average, this is pretty alright.</p>
<p>Of course, we want to make sure this model can generalize outside of the data it was trained with – let’s use it to make predictions against our validation set, too:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1">flight_validation<span class="sc" style="color: #5E5E5E;">$</span>lm_pred <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">predict</span>(</span>
<span id="cb13-2">  linear_model,</span>
<span id="cb13-3">  <span class="at" style="color: #657422;">newdata =</span> flight_validation</span>
<span id="cb13-4">)</span>
<span id="cb13-5"></span>
<span id="cb13-6"><span class="fu" style="color: #4758AB;">sqrt</span>(<span class="fu" style="color: #4758AB;">mean</span>((flight_validation<span class="sc" style="color: #5E5E5E;">$</span>lm_pred <span class="sc" style="color: #5E5E5E;">-</span> flight_validation<span class="sc" style="color: #5E5E5E;">$</span>arr_delay)<span class="sc" style="color: #5E5E5E;">^</span><span class="dv" style="color: #AD0000;">2</span>))</span>
<span id="cb13-7"><span class="fu" style="color: #4758AB;">summary</span>(<span class="fu" style="color: #4758AB;">lm</span>(arr_delay <span class="sc" style="color: #5E5E5E;">~</span> lm_pred, flight_validation))<span class="sc" style="color: #5E5E5E;">$</span>r.squared</span></code></pre></div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>[1] 14.73962</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.8684178</code></pre>
</div>
</div>
<p>R^2 remains at about 0.87 and RMSE comes in at about 14.74 minutes – which, considering delays in the validation set range from -75 to 485 minutes, feels not too bad for a naively implemented linear model.</p>
</section>
<section id="random-forest" class="level3">
<h3 class="anchored" data-anchor-id="random-forest">Random Forest</h3>
<p>So we have our first model sorted, but we need more than that to take an average! While we could average out a number of linear models with different parameters, it feels more interesting to combine a few different algorithms as component models. So let’s use <a href="https://github.com/imbs-hl/ranger">ranger</a> to implement a random forest to represent our data – fair warning, this one takes a little while to train!</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1">ranger_model <span class="ot" style="color: #003B4F;">&lt;-</span> ranger<span class="sc" style="color: #5E5E5E;">::</span><span class="fu" style="color: #4758AB;">ranger</span>(arr_delay <span class="sc" style="color: #5E5E5E;">~</span> ., <span class="at" style="color: #657422;">data =</span> flight_training)</span>
<span id="cb16-2"><span class="fu" style="color: #4758AB;">sqrt</span>(ranger_model<span class="sc" style="color: #5E5E5E;">$</span>prediction.error)</span>
<span id="cb16-3">ranger_model<span class="sc" style="color: #5E5E5E;">$</span>r.squared</span></code></pre></div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>[1] 11.08573</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9276561</code></pre>
</div>
</div>
<p>So this model has an RMSE of 11.09 and an R^2 of 0.93 – an improvement over our linear model! While we could eke out some improvements with careful tuning, it looks like this version is a good enough fit to use as an example in our ensemble. As before, we want to check out how well this model generalizes by using it to generate predictions for our validation set:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1">ranger_predictions <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">predict</span>(</span>
<span id="cb19-2">    ranger_model,</span>
<span id="cb19-3">    <span class="at" style="color: #657422;">data =</span> flight_validation</span>
<span id="cb19-4">  )</span>
<span id="cb19-5"></span>
<span id="cb19-6">flight_validation<span class="sc" style="color: #5E5E5E;">$</span>ranger_pred <span class="ot" style="color: #003B4F;">&lt;-</span> ranger_predictions<span class="sc" style="color: #5E5E5E;">$</span>predictions</span>
<span id="cb19-7"></span>
<span id="cb19-8"><span class="fu" style="color: #4758AB;">sqrt</span>(<span class="fu" style="color: #4758AB;">mean</span>((flight_validation<span class="sc" style="color: #5E5E5E;">$</span>ranger_pred <span class="sc" style="color: #5E5E5E;">-</span> flight_validation<span class="sc" style="color: #5E5E5E;">$</span>arr_delay)<span class="sc" style="color: #5E5E5E;">^</span><span class="dv" style="color: #AD0000;">2</span>))</span>
<span id="cb19-9"><span class="fu" style="color: #4758AB;">summary</span>(<span class="fu" style="color: #4758AB;">lm</span>(arr_delay <span class="sc" style="color: #5E5E5E;">~</span> ranger_pred, flight_validation))<span class="sc" style="color: #5E5E5E;">$</span>r.squared</span></code></pre></div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>[1] 10.96209</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9302306</code></pre>
</div>
</div>
<p>Our model actually performs (extremely) slightly better on the validation set!</p>
</section>
<section id="gbm" class="level3">
<h3 class="anchored" data-anchor-id="gbm">GBM</h3>
<p>So that’s two models sorted! For completeness sake, let’s implement a third and final component model, this time using the <a href="https://github.com/microsoft/LightGBM/tree/master/R-package">LightGBM</a> package to fit a gradient boosting machine. Similar to the last two, we won’t do a ton to parameterize this model – the only change I’ll make to the model fit defaults is to use 100 rounds, to let the boosting algorithm get into the same performance range as our other two models.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1">lightgbm_model <span class="ot" style="color: #003B4F;">&lt;-</span> lightgbm<span class="sc" style="color: #5E5E5E;">::</span><span class="fu" style="color: #4758AB;">lightgbm</span>(xtrain, </span>
<span id="cb22-2">                                     ytrain, </span>
<span id="cb22-3">                                     <span class="at" style="color: #657422;">nrounds =</span> <span class="dv" style="color: #AD0000;">100</span>, </span>
<span id="cb22-4">                                     <span class="at" style="color: #657422;">obj =</span> <span class="st" style="color: #20794D;">"regression"</span>, </span>
<span id="cb22-5">                                     <span class="at" style="color: #657422;">metric =</span> <span class="st" style="color: #20794D;">"rmse"</span>,</span>
<span id="cb22-6">                                     <span class="co" style="color: #5E5E5E;"># Suppress output</span></span>
<span id="cb22-7">                                     <span class="at" style="color: #657422;">force_col_wise =</span> <span class="cn" style="color: #8f5902;">TRUE</span>,</span>
<span id="cb22-8">                                     <span class="at" style="color: #657422;">verbose =</span> 0L)</span></code></pre></div>
</div>
<p>The <code>lightgbm_model</code> doesn’t have the same easy method for evaluating in-bag performance as our linear model and random forests did. We’ll skip right to the validation set instead:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1">flight_validation<span class="sc" style="color: #5E5E5E;">$</span>lightgbm_pred <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">predict</span>(</span>
<span id="cb23-2">  lightgbm_model,</span>
<span id="cb23-3">  xvalid</span>
<span id="cb23-4">)</span>
<span id="cb23-5"></span>
<span id="cb23-6"><span class="fu" style="color: #4758AB;">sqrt</span>(<span class="fu" style="color: #4758AB;">mean</span>((flight_validation<span class="sc" style="color: #5E5E5E;">$</span>lightgbm_pred <span class="sc" style="color: #5E5E5E;">-</span> flight_validation<span class="sc" style="color: #5E5E5E;">$</span>arr_delay)<span class="sc" style="color: #5E5E5E;">^</span><span class="dv" style="color: #AD0000;">2</span>))</span>
<span id="cb23-7"><span class="fu" style="color: #4758AB;">summary</span>(<span class="fu" style="color: #4758AB;">lm</span>(arr_delay <span class="sc" style="color: #5E5E5E;">~</span> lightgbm_pred, flight_validation))<span class="sc" style="color: #5E5E5E;">$</span>r.squared</span></code></pre></div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>[1] 10.4088</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9347398</code></pre>
</div>
</div>
<p>So it looks like LightGBM model performs about as well (if not marginally better than) our random forest! For reference, here are the RMSE values from each of our candidate models:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1">prediction_values <span class="ot" style="color: #003B4F;">&lt;-</span> flight_validation <span class="sc" style="color: #5E5E5E;">%&gt;%</span> </span>
<span id="cb26-2">  <span class="co" style="color: #5E5E5E;"># Only select our y and y-hat columns</span></span>
<span id="cb26-3">  <span class="fu" style="color: #4758AB;">select</span>(<span class="fu" style="color: #4758AB;">ends_with</span>(<span class="st" style="color: #20794D;">"pred"</span>), <span class="fu" style="color: #4758AB;">matches</span>(<span class="st" style="color: #20794D;">"arr_delay"</span>))</span>
<span id="cb26-4"></span>
<span id="cb26-5">prediction_plots <span class="ot" style="color: #003B4F;">&lt;-</span> prediction_values <span class="sc" style="color: #5E5E5E;">%&gt;%</span> </span>
<span id="cb26-6">  <span class="fu" style="color: #4758AB;">pivot_longer</span>(<span class="at" style="color: #657422;">cols =</span> <span class="sc" style="color: #5E5E5E;">-</span>arr_delay) <span class="sc" style="color: #5E5E5E;">%&gt;%</span> </span>
<span id="cb26-7">  <span class="fu" style="color: #4758AB;">mutate</span>(<span class="at" style="color: #657422;">name =</span> <span class="fu" style="color: #4758AB;">regmatches</span>(name, <span class="fu" style="color: #4758AB;">regexpr</span>(<span class="st" style="color: #20794D;">".*(?=_pred)"</span>, name, <span class="at" style="color: #657422;">perl =</span> <span class="cn" style="color: #8f5902;">TRUE</span>)),</span>
<span id="cb26-8">         <span class="at" style="color: #657422;">resid =</span> value <span class="sc" style="color: #5E5E5E;">-</span> arr_delay,</span>
<span id="cb26-9">         <span class="at" style="color: #657422;">name =</span> <span class="fu" style="color: #4758AB;">factor</span>(name, <span class="at" style="color: #657422;">levels =</span> <span class="fu" style="color: #4758AB;">c</span>(<span class="st" style="color: #20794D;">"lightgbm"</span>, <span class="st" style="color: #20794D;">"ranger"</span>, <span class="st" style="color: #20794D;">"lm"</span>)))</span>
<span id="cb26-10"></span>
<span id="cb26-11">prediction_plots <span class="sc" style="color: #5E5E5E;">%&gt;%</span> </span>
<span id="cb26-12">  <span class="fu" style="color: #4758AB;">group_by</span>(<span class="at" style="color: #657422;">Model =</span> name) <span class="sc" style="color: #5E5E5E;">%&gt;%</span> </span>
<span id="cb26-13">  <span class="fu" style="color: #4758AB;">summarise</span>(<span class="at" style="color: #657422;">RMSE =</span> <span class="fu" style="color: #4758AB;">sqrt</span>(<span class="fu" style="color: #4758AB;">mean</span>(resid<span class="sc" style="color: #5E5E5E;">^</span><span class="dv" style="color: #AD0000;">2</span>)), <span class="at" style="color: #657422;">.groups =</span> <span class="st" style="color: #20794D;">"drop"</span>) <span class="sc" style="color: #5E5E5E;">%&gt;%</span> </span>
<span id="cb26-14">  <span class="fu" style="color: #4758AB;">arrange</span>(RMSE) <span class="sc" style="color: #5E5E5E;">%&gt;%</span> </span>
<span id="cb26-15">  knitr<span class="sc" style="color: #5E5E5E;">::</span><span class="fu" style="color: #4758AB;">kable</span>()</span></code></pre></div>
<div class="cell-output-display">
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th style="text-align: left;">Model</th>
<th style="text-align: right;">RMSE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">lightgbm</td>
<td style="text-align: right;">10.40880</td>
</tr>
<tr class="even">
<td style="text-align: left;">ranger</td>
<td style="text-align: right;">10.96209</td>
</tr>
<tr class="odd">
<td style="text-align: left;">lm</td>
<td style="text-align: right;">14.73962</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Of course, individual metrics don’t tell the whole story – it can be helpful to look at diagnostic plots of our predictions to try and understand patterns in how our predictions match the data. For instance, “linear models are about four minutes worse on average” is all well and good in the abstract, but graphics like the one below can help us see that – for instance – linear models tend to do a bit worse around 0 minute delays (where most of the data is clustered) while our random forest performs worse on higher extremes:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1">prediction_plots <span class="sc" style="color: #5E5E5E;">%&gt;%</span> </span>
<span id="cb27-2">  <span class="fu" style="color: #4758AB;">ggplot</span>(<span class="fu" style="color: #4758AB;">aes</span>(value, arr_delay)) <span class="sc" style="color: #5E5E5E;">+</span> </span>
<span id="cb27-3">  <span class="fu" style="color: #4758AB;">geom_point</span>(<span class="at" style="color: #657422;">alpha =</span> <span class="fl" style="color: #AD0000;">0.05</span>) <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb27-4">  <span class="fu" style="color: #4758AB;">geom_abline</span>(<span class="at" style="color: #657422;">slope =</span> <span class="dv" style="color: #AD0000;">1</span>, <span class="at" style="color: #657422;">intercept =</span> <span class="dv" style="color: #AD0000;">0</span>, <span class="at" style="color: #657422;">color =</span> <span class="st" style="color: #20794D;">"red"</span>) <span class="sc" style="color: #5E5E5E;">+</span> </span>
<span id="cb27-5">  <span class="fu" style="color: #4758AB;">facet_wrap</span>(<span class="sc" style="color: #5E5E5E;">~</span> name) <span class="sc" style="color: #5E5E5E;">+</span> </span>
<span id="cb27-6">  <span class="fu" style="color: #4758AB;">theme_minimal</span>() <span class="sc" style="color: #5E5E5E;">+</span> </span>
<span id="cb27-7">  <span class="fu" style="color: #4758AB;">labs</span>(<span class="at" style="color: #657422;">x =</span> <span class="st" style="color: #20794D;">"Predicted"</span>,</span>
<span id="cb27-8">       <span class="at" style="color: #657422;">y =</span> <span class="st" style="color: #20794D;">"Actual"</span>)</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://mm218.dev/posts/2021/01/model-averaging/index_files/figure-html/ggplot-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
</section>
<section id="model-averaging" class="level2">
<h2 class="anchored" data-anchor-id="model-averaging">Model Averaging</h2>
<p>With our candidate models in tow, we’re now fully ready to move on to model averaging methods! We’ll walk through basic implementations of three methods (equal weighting, fit-based weights, and model-based estimates) and then evaluate our ensembles at the end.</p>
<section id="equal-weights" class="level3">
<h3 class="anchored" data-anchor-id="equal-weights">Equal Weights</h3>
<p>Perhaps the most obvious way to average models is to take the simple arithmetic mean of your model predictions. This method presupposes that each of your models are equally good representations of your underlying data; since that isn’t the case here, we might expect this method to not substantially reduce error overall.</p>
<p>A benefit of this method, though, is that implementation takes no time at all:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1">prediction_values <span class="ot" style="color: #003B4F;">&lt;-</span> prediction_values <span class="sc" style="color: #5E5E5E;">%&gt;%</span> </span>
<span id="cb28-2">  <span class="fu" style="color: #4758AB;">mutate</span>(<span class="at" style="color: #657422;">equal_weight_pred =</span> (lm_pred <span class="sc" style="color: #5E5E5E;">+</span> ranger_pred <span class="sc" style="color: #5E5E5E;">+</span> lightgbm_pred) <span class="sc" style="color: #5E5E5E;">/</span> <span class="dv" style="color: #AD0000;">3</span>)</span></code></pre></div>
</div>
</section>
<section id="fit-based-weights" class="level3">
<h3 class="anchored" data-anchor-id="fit-based-weights">Fit-Based Weights</h3>
<p>A slightly more involved method is to weight models based on some metric of their performance. Almost any metric with a standard definition across component models can be used (so for instance, AIC or BIC with nested models or MSE and MAPE); as we’ve been using RMSE so far, we’ll use it to weight our errors.</p>
<p>Weighting models based on fit statistics is also relatively easy in the grand scheme of data science. First, calculate the fit statistic for each of your models:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1">model_rmse <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">vapply</span>(</span>
<span id="cb29-2">  prediction_values,</span>
<span id="cb29-3">  <span class="cf" style="color: #003B4F;">function</span>(x) <span class="fu" style="color: #4758AB;">sqrt</span>(<span class="fu" style="color: #4758AB;">mean</span>((x <span class="sc" style="color: #5E5E5E;">-</span> prediction_values<span class="sc" style="color: #5E5E5E;">$</span>arr_delay)<span class="sc" style="color: #5E5E5E;">^</span><span class="dv" style="color: #AD0000;">2</span>)),</span>
<span id="cb29-4">  <span class="fu" style="color: #4758AB;">numeric</span>(<span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb29-5">  )[<span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">:</span><span class="dv" style="color: #AD0000;">3</span>] <span class="co" style="color: #5E5E5E;"># Only our 3 component models!</span></span>
<span id="cb29-6">model_rmse</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      lm_pred   ranger_pred lightgbm_pred 
     14.73962      10.96209      10.40880 </code></pre>
</div>
</div>
<p>Then, depending on your statistic, you may need to take the reciprocal of each value – as lower RMSEs are better, we need to do so here:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1">rmse_weights <span class="ot" style="color: #003B4F;">&lt;-</span> (<span class="dv" style="color: #AD0000;">1</span> <span class="sc" style="color: #5E5E5E;">/</span> (model_rmse))</span></code></pre></div>
</div>
<p>Lastly, calculate your weights as proportion of the whole set of – you can view these values as the proportion of the ensemble prediction contributed by each component:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1">rmse_weights <span class="ot" style="color: #003B4F;">&lt;-</span> rmse_weights <span class="sc" style="color: #5E5E5E;">/</span> <span class="fu" style="color: #4758AB;">sum</span>(rmse_weights)</span>
<span id="cb32-2">rmse_weights</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      lm_pred   ranger_pred lightgbm_pred 
    0.2659099     0.3575422     0.3765479 </code></pre>
</div>
</div>
<p>Making predictions with the ensemble is then relatively easy – just multiply each of your predicted values by their proportion and sum the results:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1">prediction_values <span class="ot" style="color: #003B4F;">&lt;-</span> prediction_values <span class="sc" style="color: #5E5E5E;">%&gt;%</span> </span>
<span id="cb34-2">  <span class="fu" style="color: #4758AB;">mutate</span>(<span class="at" style="color: #657422;">fit_based_pred =</span> ((lm_pred <span class="sc" style="color: #5E5E5E;">*</span> rmse_weights[<span class="st" style="color: #20794D;">"lm_pred"</span>]) <span class="sc" style="color: #5E5E5E;">+</span> </span>
<span id="cb34-3">                             (ranger_pred <span class="sc" style="color: #5E5E5E;">*</span> rmse_weights[<span class="st" style="color: #20794D;">"ranger_pred"</span>]) <span class="sc" style="color: #5E5E5E;">+</span> </span>
<span id="cb34-4">                             (lightgbm_pred <span class="sc" style="color: #5E5E5E;">*</span> rmse_weights[<span class="st" style="color: #20794D;">"lightgbm_pred"</span>])))</span></code></pre></div>
</div>
</section>
<section id="model-based-weights" class="level3">
<h3 class="anchored" data-anchor-id="model-based-weights">Model-Based Weights</h3>
<p>The last averaging method we’ll walk through is a little more involved, but still pretty comprehensible: take your model outputs, turn around, and use them as model inputs.</p>
<p><img src="https://mm218.dev/posts/2021/01/model-averaging/Inception-image.jpeg" class="img-fluid"></p>
<p>Our toy example here is a pretty good fit for this method – we already saw in our graphics that a strong linear relationship exists between our predictions and the true value, and this relationship is a little different for each model:</p>
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>`geom_smooth()` using formula 'y ~ x'</code></pre>
</div>
<div class="cell-output-display">
<p><img src="https://mm218.dev/posts/2021/01/model-averaging/index_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>From this plot, we can guess that a linear model combining our component predictions as features will be a good fit<sup>2</sup> for averaging these models. To do so, we simply need to build a linear model:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1">predictions_model <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">lm</span>(arr_delay <span class="sc" style="color: #5E5E5E;">~</span> lm_pred <span class="sc" style="color: #5E5E5E;">*</span> ranger_pred <span class="sc" style="color: #5E5E5E;">*</span> lightgbm_pred, </span>
<span id="cb36-2">                        <span class="at" style="color: #657422;">data =</span> prediction_values)</span></code></pre></div>
</div>
<p>And then use it to generate predictions just like our original component linear model:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1">prediction_values<span class="sc" style="color: #5E5E5E;">$</span>model_based_pred <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">predict</span>(</span>
<span id="cb37-2">  predictions_model,</span>
<span id="cb37-3">  <span class="at" style="color: #657422;">newdata =</span> prediction_values</span>
<span id="cb37-4">)</span></code></pre></div>
</div>
<p>Note that if we saw non-linear relationships between our predictions and true values, we’d want to rely on non-linear methods to average out predictions; it just so happens that our models are already pretty strong fits for the underlying data and can be well-represented with simple linear regression.</p>
</section>
</section>
<section id="howd-we-do" class="level2">
<h2 class="anchored" data-anchor-id="howd-we-do">How’d We Do?</h2>
<p>Now that we have our ensemble models prepared, it’s time to evaluate all of our models out against our testing set!</p>
<p>The first step is to generate predictions for the test set using our component models:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1">flight_testing<span class="sc" style="color: #5E5E5E;">$</span>lm_pred <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">predict</span>(</span>
<span id="cb38-2">  linear_model,</span>
<span id="cb38-3">  <span class="at" style="color: #657422;">newdata =</span> flight_testing</span>
<span id="cb38-4">)</span>
<span id="cb38-5"></span>
<span id="cb38-6">ranger_predictions <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">predict</span>(</span>
<span id="cb38-7">    ranger_model,</span>
<span id="cb38-8">    <span class="at" style="color: #657422;">data =</span> flight_testing</span>
<span id="cb38-9">  )</span>
<span id="cb38-10"></span>
<span id="cb38-11">flight_testing<span class="sc" style="color: #5E5E5E;">$</span>ranger_pred <span class="ot" style="color: #003B4F;">&lt;-</span> ranger_predictions<span class="sc" style="color: #5E5E5E;">$</span>predictions</span>
<span id="cb38-12"></span>
<span id="cb38-13">flight_testing<span class="sc" style="color: #5E5E5E;">$</span>lightgbm_pred <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">predict</span>(</span>
<span id="cb38-14">  lightgbm_model,</span>
<span id="cb38-15">  xtest</span>
<span id="cb38-16">)</span></code></pre></div>
</div>
<p>We can use those predictions to generate our ensemble predictions. Note that we’re still using the weights and models calibrated on the validation data – we (theoretically) shouldn’t know the “true” values for the test set, so we can’t re-weight our averages now!</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1">flight_testing <span class="ot" style="color: #003B4F;">&lt;-</span> flight_testing <span class="sc" style="color: #5E5E5E;">%&gt;%</span> </span>
<span id="cb39-2">  <span class="fu" style="color: #4758AB;">mutate</span>(<span class="at" style="color: #657422;">equal_weight_pred =</span> (lm_pred <span class="sc" style="color: #5E5E5E;">+</span> ranger_pred <span class="sc" style="color: #5E5E5E;">+</span> lightgbm_pred) <span class="sc" style="color: #5E5E5E;">/</span> <span class="dv" style="color: #AD0000;">3</span>)</span>
<span id="cb39-3"></span>
<span id="cb39-4">flight_testing <span class="ot" style="color: #003B4F;">&lt;-</span> flight_testing <span class="sc" style="color: #5E5E5E;">%&gt;%</span> </span>
<span id="cb39-5">  <span class="fu" style="color: #4758AB;">mutate</span>(<span class="at" style="color: #657422;">fit_based_pred =</span> ((lm_pred <span class="sc" style="color: #5E5E5E;">*</span> rmse_weights[<span class="st" style="color: #20794D;">"lm_pred"</span>]) <span class="sc" style="color: #5E5E5E;">+</span> </span>
<span id="cb39-6">                             (ranger_pred <span class="sc" style="color: #5E5E5E;">*</span> rmse_weights[<span class="st" style="color: #20794D;">"ranger_pred"</span>]) <span class="sc" style="color: #5E5E5E;">+</span> </span>
<span id="cb39-7">                             (lightgbm_pred <span class="sc" style="color: #5E5E5E;">*</span> rmse_weights[<span class="st" style="color: #20794D;">"lightgbm_pred"</span>])))</span>
<span id="cb39-8"></span>
<span id="cb39-9">flight_testing<span class="sc" style="color: #5E5E5E;">$</span>model_based_pred <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">predict</span>(</span>
<span id="cb39-10">  predictions_model,</span>
<span id="cb39-11">  <span class="at" style="color: #657422;">newdata =</span> flight_testing</span>
<span id="cb39-12">)</span></code></pre></div>
</div>
<div class="cell">

</div>
<p>So how’d we do? Let’s check out the RMSE for each of our models:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1">prediction_values <span class="ot" style="color: #003B4F;">&lt;-</span> flight_testing <span class="sc" style="color: #5E5E5E;">%&gt;%</span> </span>
<span id="cb40-2">  <span class="fu" style="color: #4758AB;">select</span>(<span class="fu" style="color: #4758AB;">ends_with</span>(<span class="st" style="color: #20794D;">"pred"</span>), <span class="fu" style="color: #4758AB;">matches</span>(<span class="st" style="color: #20794D;">"arr_delay"</span>))</span>
<span id="cb40-3"></span>
<span id="cb40-4">prediction_plots <span class="ot" style="color: #003B4F;">&lt;-</span> prediction_values <span class="sc" style="color: #5E5E5E;">%&gt;%</span> </span>
<span id="cb40-5">  <span class="fu" style="color: #4758AB;">pivot_longer</span>(<span class="at" style="color: #657422;">cols =</span> <span class="sc" style="color: #5E5E5E;">-</span>arr_delay) <span class="sc" style="color: #5E5E5E;">%&gt;%</span> </span>
<span id="cb40-6">  <span class="fu" style="color: #4758AB;">mutate</span>(<span class="at" style="color: #657422;">name =</span> <span class="fu" style="color: #4758AB;">regmatches</span>(name, <span class="fu" style="color: #4758AB;">regexpr</span>(<span class="st" style="color: #20794D;">".*(?=_pred)"</span>, name, <span class="at" style="color: #657422;">perl =</span> <span class="cn" style="color: #8f5902;">TRUE</span>)),</span>
<span id="cb40-7">         <span class="at" style="color: #657422;">resid =</span> value <span class="sc" style="color: #5E5E5E;">-</span> arr_delay,</span>
<span id="cb40-8">         <span class="at" style="color: #657422;">name =</span> <span class="fu" style="color: #4758AB;">factor</span>(name, </span>
<span id="cb40-9">                       <span class="at" style="color: #657422;">levels =</span> <span class="fu" style="color: #4758AB;">c</span>(<span class="st" style="color: #20794D;">"lightgbm"</span>, <span class="st" style="color: #20794D;">"ranger"</span>, <span class="st" style="color: #20794D;">"lm"</span>,</span>
<span id="cb40-10">                                  <span class="st" style="color: #20794D;">"model_based"</span>, <span class="st" style="color: #20794D;">"fit_based"</span>, <span class="st" style="color: #20794D;">"equal_weight"</span>)))</span>
<span id="cb40-11"></span>
<span id="cb40-12">prediction_plots <span class="sc" style="color: #5E5E5E;">%&gt;%</span> </span>
<span id="cb40-13">  <span class="fu" style="color: #4758AB;">group_by</span>(<span class="at" style="color: #657422;">Model =</span> name) <span class="sc" style="color: #5E5E5E;">%&gt;%</span> </span>
<span id="cb40-14">  <span class="fu" style="color: #4758AB;">summarise</span>(<span class="at" style="color: #657422;">RMSE =</span> <span class="fu" style="color: #4758AB;">sqrt</span>(<span class="fu" style="color: #4758AB;">mean</span>(resid<span class="sc" style="color: #5E5E5E;">^</span><span class="dv" style="color: #AD0000;">2</span>)), <span class="at" style="color: #657422;">.groups =</span> <span class="st" style="color: #20794D;">"drop"</span>) <span class="sc" style="color: #5E5E5E;">%&gt;%</span> </span>
<span id="cb40-15">  <span class="fu" style="color: #4758AB;">arrange</span>(RMSE) <span class="sc" style="color: #5E5E5E;">%&gt;%</span> </span>
<span id="cb40-16">  knitr<span class="sc" style="color: #5E5E5E;">::</span><span class="fu" style="color: #4758AB;">kable</span>()</span></code></pre></div>
<div class="cell-output-display">
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th style="text-align: left;">Model</th>
<th style="text-align: right;">RMSE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">model_based</td>
<td style="text-align: right;">9.492409</td>
</tr>
<tr class="even">
<td style="text-align: left;">lightgbm</td>
<td style="text-align: right;">10.290113</td>
</tr>
<tr class="odd">
<td style="text-align: left;">ranger</td>
<td style="text-align: right;">10.968544</td>
</tr>
<tr class="even">
<td style="text-align: left;">fit_based</td>
<td style="text-align: right;">11.057728</td>
</tr>
<tr class="odd">
<td style="text-align: left;">equal_weight</td>
<td style="text-align: right;">11.311836</td>
</tr>
<tr class="even">
<td style="text-align: left;">lm</td>
<td style="text-align: right;">14.621943</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1">prediction_plots <span class="sc" style="color: #5E5E5E;">%&gt;%</span> </span>
<span id="cb41-2">  <span class="fu" style="color: #4758AB;">ggplot</span>(<span class="fu" style="color: #4758AB;">aes</span>(value, arr_delay)) <span class="sc" style="color: #5E5E5E;">+</span> </span>
<span id="cb41-3">  <span class="fu" style="color: #4758AB;">geom_point</span>(<span class="at" style="color: #657422;">alpha =</span> <span class="fl" style="color: #AD0000;">0.05</span>) <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb41-4">  <span class="fu" style="color: #4758AB;">geom_abline</span>(<span class="at" style="color: #657422;">slope =</span> <span class="dv" style="color: #AD0000;">1</span>, <span class="at" style="color: #657422;">intercept =</span> <span class="dv" style="color: #AD0000;">0</span>, <span class="at" style="color: #657422;">color =</span> <span class="st" style="color: #20794D;">"red"</span>) <span class="sc" style="color: #5E5E5E;">+</span> </span>
<span id="cb41-5">  <span class="fu" style="color: #4758AB;">facet_wrap</span>(<span class="sc" style="color: #5E5E5E;">~</span> name) <span class="sc" style="color: #5E5E5E;">+</span> </span>
<span id="cb41-6">  <span class="fu" style="color: #4758AB;">theme_minimal</span>() <span class="sc" style="color: #5E5E5E;">+</span> </span>
<span id="cb41-7">  <span class="fu" style="color: #4758AB;">labs</span>(<span class="at" style="color: #657422;">x =</span> <span class="st" style="color: #20794D;">"Predicted"</span>,</span>
<span id="cb41-8">       <span class="at" style="color: #657422;">y =</span> <span class="st" style="color: #20794D;">"Actual"</span>)</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://mm218.dev/posts/2021/01/model-averaging/index_files/figure-html/unnamed-chunk-20-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Cool – our model-based ensemble actually performed better than any of the components! While the equal weight and fit-based averages were pretty middle-of-the-road, in other settings these methods can also help to reduce bias in predictions and produce estimates with less variance than any of the component models.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Model averaging can be a powerful tool for reducing model bias and addressing the implicit uncertainty in attempting to pick the “best” model for a situation. While plenty of complex and computationally expensive approaches to averaging exist – and can greatly improve model performance – simpler ensemble methods can provide the same benefits without necessarily incurring the same costs.</p>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Dormann" class="csl-entry">
Dormann, Carsten F., Justin M. Calabrese, Gurutzeta Guillera-Arroita, Eleni Matechou, Volker Bahn, Kamil Bartoń, Colin M. Beale, et al. 2018. <span>“Model Averaging in Ecology: A Review of Bayesian, Information-Theoretic, and Tactical Approaches for Predictive Inference.”</span> <em>Ecological Monographs</em> 88 (4): 485–504. https://doi.org/<a href="https://doi.org/10.1002/ecm.1309">https://doi.org/10.1002/ecm.1309</a>.
</div>
<div id="ref-Wintle" class="csl-entry">
Wintle, B. A., M. A. McCarthy, C. T. Volinsky, and R. P. Kavanagh. 2003. <span>“The Use of Bayesian Model Averaging to Better Represent Uncertainty in Ecological Models.”</span> <em>Conservation Biology</em> 17 (6): 1579–90. https://doi.org/<a href="https://doi.org/10.1111/j.1523-1739.2003.00614.x">https://doi.org/10.1111/j.1523-1739.2003.00614.x</a>.
</div>
</div></section><section class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>See table 1 of Dormann et. al.&nbsp;for a partial list.↩︎</p></li>
<li id="fn2"><p>No pun intended.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>R</category>
  <category>Data science</category>
  <guid>https://mm218.dev/posts/2021/01/model-averaging/index.html</guid>
  <pubDate>Mon, 18 Jan 2021 05:00:00 GMT</pubDate>
  <media:content url="https://mm218.dev/posts/2021/01/model-averaging/model_avg.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Some Updates</title>
  <dc:creator>Mike Mahoney</dc:creator>
  <link>https://mm218.dev/posts/2020/10/index.html</link>
  <description><![CDATA[ 




<p>It’s been a busy few months! Rather than try to make separate update posts for everything I’ve been up to, here’s a list of the top bullets from my past four months.</p>
<section id="new-digs-and-new-gigs" class="level2">
<h2 class="anchored" data-anchor-id="new-digs-and-new-gigs">New Digs and New Gigs</h2>
<p>I’ve left Boston and left Wayfair to take a PhD position at SUNY-ESF in Syracuse, working with Colin Beier and Aidan Ackerman to make 3D landscape visualizations as a way to improve the interpretability of ecological models and help democratize scientific outputs.</p>
</section>
<section id="paper-stem-size-selectivity-is-stronger-than-species-preferences-for-beaver-a-central-place-forager" class="level2">
<h2 class="anchored" data-anchor-id="paper-stem-size-selectivity-is-stronger-than-species-preferences-for-beaver-a-central-place-forager">Paper: Stem size selectivity is stronger than species preferences for beaver, a central place forager</h2>
<p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0378112720311002">My first first-authored paper is out in Forest Ecology and Management!</a> I wrote a little about the process of this paper, from start to finish, <a href="https://systematica.substack.com/p/the-making-of">on my extremely short-lived newsletter.</a></p>
</section>
<section id="tweetbots" class="level2">
<h2 class="anchored" data-anchor-id="tweetbots">Tweetbots</h2>
<p>I’ve now got a small army of robots living in the corner of my apartment, tweeting out to their heart’s content. At the moment, I’ve got three retweet bots running off the original <a href="https://github.com/mikemahoney218/retweet_bot">ecology_tweets codebase</a>, namely <a href="https://twitter.com/ecology_tweets"><span class="citation" data-cites="ecology_tweets">@ecology_tweets</span></a>, <a href="https://twitter.com/rstats_tweets"><span class="citation" data-cites="rstats_tweets">@rstats_tweets</span></a> (a more heavily-filtered alternative to the more popular rstatstweets bot), and <a href="https://twitter.com/30daymap_tweets"><span class="citation" data-cites="30daymap_tweets">@30daymap_tweets</span></a>, built for the #30DayMapChallenge.</p>
<p>More interesting are the two GPT-2 “AI” tweetbots now running, including <a href="https://twitter.com/fortunes_teller"><span class="citation" data-cites="fortunes_teller">@fortunes_teller</span></a> and <a href="https://twitter.com/fund_me_please_"><span class="citation" data-cites="fund_me_please_">@fund_me_please_</span></a>. The former is trained against a collection of <code>fortunes</code> packages from various *nix distros and the R fortunes package, while the latter was run against 150 GRFP personal statements and is now tweeting out some frankly bizarre applications of its own making.</p>
</section>
<section id="terrainr" class="level2">
<h2 class="anchored" data-anchor-id="terrainr">{terrainr}</h2>
<p>I’ve got a new R package out, the first real “product” from my PhD. {terrainr} wraps the USGS National Map family of APIs to help users download geospatial data for their areas of interest, and provides functionality to turn those files into tiles that can be imported into Unity for 3D landscape visualization:</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://mm218.dev/posts/2020/10/terrainr.jpg" class="img-fluid figure-img" width="2126"></p>
<p></p><figcaption class="figure-caption">A 3D landscape visualization of the area southeast of Mt. Whitney, California, USA.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>I love writing packages with visual outputs. I love writing packages with visual outputs that look like <em>this</em>.</p>
</section>
<section id="misc" class="level2">
<h2 class="anchored" data-anchor-id="misc">Misc</h2>
<p>I bought a <a href="https://www.instagram.com/p/CDJVN-JlB5R/">pen plotter.</a></p>


</section>

 ]]></description>
  <category>R</category>
  <category>Twitter</category>
  <category>phd</category>
  <category>terrainr</category>
  <category>beaver</category>
  <guid>https://mm218.dev/posts/2020/10/index.html</guid>
  <pubDate>Fri, 16 Oct 2020 04:00:00 GMT</pubDate>
  <media:content url="https://mm218.dev/posts/2020/10/terrainr.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Make a Retweet Bot in R</title>
  <dc:creator>Mike Mahoney</dc:creator>
  <link>https://mm218.dev/posts/2020/06/index.html</link>
  <description><![CDATA[ 




<p>A while back, I made a <a href="https://twitter.com/ecology_tweets">tweetbot</a> that retweets a set of ecology-related hashtags, in order to signal boost ecology content in a similar manner to <a href="https://twitter.com/statstwitbot">statsbot</a> or <a href="https://twitter.com/PlotterTweeter">Plotter Bot</a>. The code to do this is pretty simple – made almost trivial by the <a href="https://rtweet.info/">rtweet</a> package – but I found that environmental hashtags have a pretty low signal-to-noise ratio, driven down by various political and industry groups, as well as trolls.</p>
<p>I didn’t want to get into the business of content filtering, so instead I started looking for other markers that a tweet was – or wasn’t – worth promoting, and have gotten to what I believe is a respectable place with my filtration. So I’ve <a href="https://github.com/mikemahoney218/retweet_bot/tree/master">open-sourced the code</a> (without the specific values I use to filter) for anyone else who might be interested in setting up their own automated retweet app.</p>



 ]]></description>
  <category>R</category>
  <category>Twitter</category>
  <category>ecology_tweets</category>
  <guid>https://mm218.dev/posts/2020/06/index.html</guid>
  <pubDate>Sat, 20 Jun 2020 04:00:00 GMT</pubDate>
</item>
<item>
  <title>Installing the TIG stack on Raspberry Pi</title>
  <dc:creator>Mike Mahoney</dc:creator>
  <link>https://mm218.dev/posts/2020/05/index.html</link>
  <description><![CDATA[ 




<section id="setting-up-influxdb-telegraf-and-grafana-on-raspberry-pi" class="level2">
<h2 class="anchored" data-anchor-id="setting-up-influxdb-telegraf-and-grafana-on-raspberry-pi">Setting Up InfluxDB, Telegraf, and Grafana on Raspberry Pi</h2>
<div class="cell">
<div class="cell-output-display">
<p><img src="https://mm218.dev/posts/2020/05/grafana_dash.webp" class="img-fluid"></p>
</div>
</div>
<section id="tldr" class="level3">
<h3 class="anchored" data-anchor-id="tldr">tl;dr</h3>
<p>Do the following in a shell you’ve already auth’d into sudo on:</p>
<pre><code>sudo apt update
sudo apt upgrade

wget -qO- https://repos.influxdata.com/influxdb.key | sudo apt-key add -
# change "buster" as appropriate for your distro
echo "deb https://repos.influxdata.com/debian buster stable" | sudo tee /etc/apt/sources.list.d/influxdb.list
sudo apt update
sudo apt install influxdb
sudo systemctl unmask influxdb
sudo systemctl enable influxdb
sudo systemctl start influxdb

# you can find the current telegraf release here: https://portal.influxdata.com/downloads/
wget https://dl.influxdata.com/telegraf/releases/telegraf-1.14.2_linux_armhf.tar.gz
tar xf telegraf-1.14.2_linux_armhf.tar.gz
sudo systemctl enable --now telegraf
rm telegraf-1.14.2_linux_armhf.tar.gz

sudo apt-get install -y adduser libfontconfig1
# you can find the current grafana release here: https://grafana.com/grafana/download
wget https://dl.grafana.com/oss/release/grafana_6.7.3_armhf.deb
sudo dpkg -i grafana_6.7.3_armhf.deb
sudo systemctl enable --now grafana-server
rm grafana_6.7.3_armhf.deb</code></pre>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>This should cause all three services to start on system boot. You’ll need to configure Telegraf to actually write to your local Influx instance at http://127.0.0.1:8086 (there’s a sample config under the <code>Telegraf</code> part of the post), then set up Grafana to read from Influx (at the same port) via the UI at localhost:3000.</p>
<hr>

<p><br><br></p>
</section>
<section id="setting-up-the-tig-stack-on-raspberry-pi" class="level3">
<h3 class="anchored" data-anchor-id="setting-up-the-tig-stack-on-raspberry-pi">Setting up the TIG stack on Raspberry Pi</h3>
<p>I’m getting a little cabin-fevery as the 2020 quarantine moves into its third month. To try and defray some of the extra energy, I’ve been hacking on a Pi I set up with a <a href="https://openvpn.net/">Pi-hole</a> and <a href="https://openvpn.net/">openvpn</a> server about a month ago.</p>
<p>One of the cool things about the Pi-hole is that it gives you a little at-a-glance view of how your machine is doing, including CPU load, memory utilization, and temperature. This window into system stats made me realize that my little box is packing <em>heat</em>:</p>
<p><img src="https://mm218.dev/posts/2020/05/pihole_data.webp" class="img-fluid"></p>
<p>I’m running a Pi 4, which <a href="https://www.theregister.co.uk/2019/07/22/raspberry_pi_4_too_hot_to_handle/">is known for generating more heat than it can handle</a>, so temperatures of ~60 C (<a href="https://www.raspberrypi.org/forums/viewtopic.php?t=39953">the upper range of “safe”</a>) isn’t too shocking – but with summer coming and me planning to add some load to this machine in the near future, I wanted to set up monitoring to make sure my box wasn’t going to melt on me. This also has the side benefit that I’ll have a metrics system already in place for anything else I stand up on this machine.</p>
<p>Enter the TIG stack. TIG – <strong>T</strong>elegraf, <strong>I</strong>nfluxDB, and <strong>G</strong>rafana – is a suite of open-source solutions for collecting, storing, and visualizing time-series data, like the sort you’ll get from repeatedly measuring system temperature.</p>
<p>This tutorial will walk you through setting up each of these services separately. These steps were tested on a Raspberry Pi 4 running Raspbian Buster, so other configurations might require some tweaking.</p>
<p>All of the code here should be run in a terminal on your Raspberry Pi unless I specify it needs to go somewhere else. To make sure you’re not going to run into dependency hell, it’s a good idea to run <code>sudo apt update &amp;&amp; sudo apt upgrade</code> before installing any of the stack.</p>
<hr>

<p><br><br></p>
</section>
<section id="influxdb" class="level3">
<h3 class="anchored" data-anchor-id="influxdb">InfluxDB</h3>
<p>First up, we need to set up our InfluxDB instance. This database is where our Telegraf instance will send metrics and where Grafana will read from, so it makes sense to stand it up first!</p>
<p>Installing the service is easy enough – we just need to add Influx’s authentication key, add their repository to our trusted sources, and then install it via <code>apt</code>:</p>
<pre><code>wget -qO- https://repos.influxdata.com/influxdb.key | sudo apt-key add -
# change "buster" as appropriate for your distro
echo "deb https://repos.influxdata.com/debian buster stable" | sudo tee /etc/apt/sources.list.d/influxdb.list
sudo apt update
sudo apt install influxdb influxdb-client</code></pre>
<p>
</p>
<p>Now we want to actually start the database, and tell our system to start it after reboots – since we’re expecting to always be collecting metrics via Telegraf, we need to make sure that we always have a place to write to, as well. This is a quick two-liner using <code>systemctl</code> – we first need to <code>unmask</code> Influx, which will let us add it as a service, then tell our Pi to start the service both right now and every time the system restarts via the <code>enable --now</code> command:</p>
<pre><code>sudo systemctl unmask influxdb
sudo systemctl enable --now influxdb</code></pre>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>After this, you should be able to run <code>systemctl status influxdb</code> to see the service status – if everything went according to plan, you should see <code>Active: active (running)</code> around line 3 of the output.</p>
<p>At this point, it’s probably healthy to add authentication to your Influx instance if your pi is exposed to external networks. You can set up a basic admin account via:</p>
<pre><code>influx
CREATE USER admin WITH PASSWORD '&lt;password&gt;' WITH ALL PRIVILEGES</code></pre>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>You can then force HTTP authentication by adding the following under the HTTP header in <code>/etc/influxdb/influxdb.conf</code>:</p>
<pre><code>[HTTP]
auth-enabled = true
pprof-enabled = true
pprof-auth-enabled = true
ping-auth-enabled = true</code></pre>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>The changes take effect the next time your service starts, which you can trigger via <code>sudo systemctl restart influxdb</code>.</p>
<hr>

<p><br><br></p>
</section>
<section id="telegraf" class="level3">
<h3 class="anchored" data-anchor-id="telegraf">Telegraf</h3>
<p>With Influx up and running, it’s time for us to start writing records, which means standing up Telegraf!</p>
<p>Telegraf is updated pretty frequently, so it’s a good idea to check <a href="https://portal.influxdata.com/downloads/">the release page</a> to see what version you should be installing. At the time of writing, the current version is 1.14.2, so I ran the following to install Telegraf on my machine:</p>
<pre><code>wget https://dl.influxdata.com/telegraf/releases/telegraf_1.14.2-1_armhf.deb
sudo dpkg -i telegraf_1.14.2-1_armhf.deb
rm telegraf_1.14.2-1_armhf.deb</code></pre>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>We now have Telegraf installed on our machine, but the service won’t do us much good before we set up our configuration, located at <code>/etc/telegraf/telegraf.conf</code>. Telegraf operates by coordinating a bunch of “plugins”, which work to collect and write data to and from different sources. You can see the full list of plugins <a href="https://github.com/influxdata/telegraf/tree/master/plugins">at Telegraf’s GitHub repo</a>, and activate each by copying the configuration from the plugin’s readme into your <code>/etc/telegraf/telegraf.conf</code> file.</p>
<p>I spent far too much time pouring over the various plugins and wound up with the following configuration file – you can use this to overwrite your default <code>telegraph.conf</code> file and start collecting metrics right away, or you can spend the time now to set up your instance to suit your own particular needs. Just make sure you edit your <code>[[outputs.influxdb]]</code> to include the following:</p>
<pre><code>[[outputs.influxdb]]
   ## The full HTTP or UDP URL for your InfluxDB instance.
   urls = ["http://127.0.0.1:8086"] # required</code></pre>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>My full configuration looks like this:</p>
<pre><code>[agent]
   # Batch size of values that Telegraf sends to output plugins.
   metric_batch_size = 1000
   # Default data collection interval for inputs.
   interval = "30s"
   # Added degree of randomness in the collection interval.
   collection_jitter = "5s"
   # Send output every 5 seconds
   flush_interval = "5s"
   # Buffer size for failed writes.
   metric_buffer_limit = 10000
   # Run in quiet mode, i.e don't display anything on the console.
   quiet = true
[[inputs.ping]] # # Ping given url(s) and return statistics
## urls to ping
urls = ["www.github.com","www.amazon.com","1.1.1.1","www.mm218.dev"]
## number of pings to send per collection (ping -c )
count = 3
## interval, in s, at which to ping. 0 == default (ping -i )
ping_interval = 15.0
## per-ping timeout, in s. 0 == no timeout (ping -W )
timeout = 10.0
## interface to send ping from (ping -I )
interface = "wlan0"
[[inputs.system]]
[[inputs.influxdb]]
  ## Works with InfluxDB debug endpoints out of the box,
  ## but other services can use this format too.
  ## See the influxdb plugin's README for more details.

  ## Multiple URLs from which to read InfluxDB-formatted JSON
  ## Default is "http://localhost:8086/debug/vars".
  urls = [
    "http://localhost:8086/debug/vars"
  ]
  ## http request &amp; header timeout
  timeout = "5s"
[[inputs.disk]]
  ## Ignore mount points by filesystem type.
  ignore_fs = ["tmpfs", "devtmpfs", "devfs", "iso9660", "overlay", "aufs", "squashfs"]
[[inputs.diskio]]
[[inputs.internal]]
  ## If true, collect telegraf memory stats.
  collect_memstats = true
[[inputs.mem]]
[[inputs.processes]]
# custom temperature script
# https://github.com/mikemahoney218/pi-admin/blob/master/telegraf-scripts/systemp.sh
[[inputs.exec]]
  commands = ["sh /tmp/telegraf-scripts/systemp.sh"]
  timeout = "5s"
  data_format = "influx"
[[outputs.influxdb]]
   ## The full HTTP or UDP URL for your InfluxDB instance.
   urls = ["http://127.0.0.1:8086"] # required
   ## The target database for metrics (telegraf will create it if not exists).
   database = "pi_logs" # required
   ## Name of existing retention policy to write to.  Empty string writes to
   ## the default retention policy.
   retention_policy = ""
   ## Write consistency (clusters only), can be: "any", "one", "quorum", "all"
   write_consistency = "any"
   ## Write timeout (for the InfluxDB client), formatted as a string.
   ## If not provided, will default to 5s. 0s means no timeout (not recommended).
   timeout = "10s"</code></pre>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>In putting all this together, I found out that the Telegraf plugin to measure system temperature – the thing that got me down this rabbit hole in the first place – doesn’t actually work on Raspberry Pi systems. As a workaround, I threw together <a href="https://github.com/mikemahoney218/pi-admin/blob/master/telegraf-scripts/systemp.sh">a simple one-liner in Bash</a>:</p>
<pre><code>echo "systemp temp=`cat /sys/class/thermal/thermal_zone0/temp`"</code></pre>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>I saved that script off to <code>/tmp/telegraf-scripts/systemp.sh</code>, then added it to my <code>telegraf.conf</code> in the brick:</p>
<pre><code>[[inputs.exec]]
  commands = ["sh /tmp/telegraf-scripts/systemp.sh"]
  timeout = "5s"
  data_format = "influx"</code></pre>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>If you’re not worried about measuring temperature, you don’t need (or want) to include that section in your <code>telegraf.conf</code>.</p>
<p>If you set up HTTP authentication for your Influx instance, you’re going to want to add <code>username</code> and <code>password</code> fields under the <code>[[outputs.influxdb]]</code></p>
<p>With our configuration in place, all that’s left now is to start and enable the Telegraf service:</p>
<pre><code>sudo systemctl enable --now telegraf</code></pre>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>As before, you should be able to see that the service is running without issue by running <code>systemctl status telegraf</code>.</p>
<p>Now that your service is running, any changes that you make to your <code>telegraf.config</code> file will only take effect after the service restarts. You can always restart the service using <code>sudo systemctl restart telegraf</code>, but I personally kept forgetting to do so (and then was surprised when my metrics weren’t showing up in Influx). To deal with that, <a href="https://github.com/mikemahoney218/pi-admin/tree/master/telegraf-watcher">I wrote an extremely-micro service that restarts Telegraf for me</a>.</p>
<hr>

<p><br><br></p>
</section>
<section id="grafana" class="level3">
<h3 class="anchored" data-anchor-id="grafana">Grafana</h3>
<p>We’re finally onto our last service, the G in the TIG stack, Grafana. A quick word of warning: <strong>don’t try to</strong> <code>sudo apt install grafana</code>. The main repository has an outdated version of Grafana, which will leave you stuck at a blank screen when you try to log on for the first time.</p>
<p>Instead, we’ll install Grafana via dpkg, like we did with Telegraf. Check for the most current version at <a href="https://grafana.com/grafana/download">Grafana’s downloads page</a>. At the time of writing, I was installing version 6.7.3, so my commands to install looked like this:</p>
<pre><code>wget https://dl.grafana.com/oss/release/grafana_6.7.3_armhf.deb
sudo dpkg -i grafana_6.7.3_armhf.deb
sudo systemctl enable --now grafana-server
rm grafana_6.7.3_armhf.deb</code></pre>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>Unlike Influx and Telegraf, Grafana can be managed almost entirely from a UI. Boot up <code>localhost:3000</code> on your Pi and log in using <code>admin</code> for both your username and password – you’ll be prompted to change it once you’re logged in for the first time.</p>
<p>You’ll then want to add your local Influx instance as a datasource for Grafana. Assuming you’ve followed along until now, the URL for your Influx instance is <code>http://localhost:8086</code>. You’ll also want to add whatever database Telegraf is writing to – in the sample configuration I posted, the database name is <code>pi_logs</code>, but you can find yours by looking for the <code>database</code> field under <code>[[outputs.influxdb]]</code>. If you added authentication to your Influx instance, you’ll also want to turn on <code>basic auth</code> and provide your database credentials.</p>
<hr>

<p><br><br></p>
</section>
<section id="get-graphing" class="level3">
<h3 class="anchored" data-anchor-id="get-graphing">Get Graphing</h3>
<p>And with that, you should have everything you need to start monitoring your Pi – and, with a little elbow grease, anything your Pi can touch! While it certainly feels a little like overkill, I’ve now got state-of-the art tracking and system metrics for my Pi, letting me confirm beyond a shadow of a doubt that… my Pi is running too hot. With all the time I spent on this, maybe I should have just bought a fan.</p>
<p>But hey – would a fan look <em>this</em> good?</p>
<p><img src="https://mm218.dev/posts/2020/05/full_grafana.webp" class="img-fluid"></p>


</section>
</section>

 ]]></description>
  <category>Raspberry Pi</category>
  <category>Tutorials</category>
  <category>Data Visualization</category>
  <category>Monitoring</category>
  <category>Telegraf</category>
  <category>InfluxDB</category>
  <category>Grafana</category>
  <guid>https://mm218.dev/posts/2020/05/index.html</guid>
  <pubDate>Sun, 03 May 2020 04:00:00 GMT</pubDate>
  <media:content url="https://mm218.dev/posts/2020/05/pihole_data.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>A minimalist visualization of Coronavirus rates</title>
  <dc:creator>Mike Mahoney</dc:creator>
  <link>https://mm218.dev/posts/2020/04/corona-viz/index.html</link>
  <description><![CDATA[ 




<p>I had been getting frustrated with not being able to quickly find coronavirus data for my area, and not being able to see recent trends without framing and interpretation. So I grabbed down the John Hopkins CSSE data and made a quick Shiny app to visualize case and death rates. I’m trying to not contribute to the constant noise surrounding the ongoing pandemic, but having a way to see these numbers without an overwhelming amount of surrounding editorialization has made me feel like I understand the world a bit better.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1">knitr<span class="sc" style="color: #5E5E5E;">::</span><span class="fu" style="color: #4758AB;">include_graphics</span>(<span class="st" style="color: #20794D;">"covid.png"</span>)</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://mm218.dev/posts/2020/04/corona-viz/covid.png" class="img-fluid" style="width:100.0%"></p>
</div>
</div>
<p><a href="https://mm218.shinyapps.io/corona_data_explore/">The app lives at this link</a>. Thanks to R Studio, who are providing free hosting for coronavirus apps through the pandemic.</p>



 ]]></description>
  <category>R</category>
  <guid>https://mm218.dev/posts/2020/04/corona-viz/index.html</guid>
  <pubDate>Mon, 27 Apr 2020 04:00:00 GMT</pubDate>
</item>
<item>
  <title>Making Excellent Visualizations</title>
  <dc:creator>Mike Mahoney</dc:creator>
  <link>https://mm218.dev/posts/2020/04/making-excellent-viz/index.html</link>
  <description><![CDATA[ 




<p>As we move into our final section, it’s time to dwell on our final mantra:</p>
<section id="ink-is-cheap.-electrons-are-even-cheaper." class="level3">
<h3 class="anchored" data-anchor-id="ink-is-cheap.-electrons-are-even-cheaper.">Ink is cheap. Electrons are even cheaper.</h3>
<p>This is a fancy, dogmatic way to say: Make more than one chart. It’s rare that your first try is going to produce your best looking output. Play around with your data set, try out different visuals, and keep the concepts we’ve talked about in mind. Your graphs will be all the better for it. In this section, we’ll talk about solutions to some of the most common problems people have with making charts:</p>
</section>
<section id="dealing-with-big-data-sets" class="level3">
<h3 class="anchored" data-anchor-id="dealing-with-big-data-sets">Dealing with big data sets</h3>
<p>Think back to the diamonds data set we used in the last section. It contains data on 54,000 individual diamonds, including the carat and sale price for each. If we wanted to compare those two continuous variables, we might think a scatter plot would be a good way to do so:</p>
<p><img src="https://mm218.dev/posts/2020/04/making-excellent-viz/making-1-1.png" class="img-fluid"></p>
<p>Unfortunately, it seems like 54,000 points is a few too many for this plot to do us much good! This is a clear case of what’s called <em>overplotting</em> – we simply have too much data on a single graph.</p>
<p>There are three real solutions to this problem. First off, we could decide simply that we want to refactor our chart, and instead show how a metric – such as average sale price – changes at different carats, rather than how our data is distributed:</p>
<p><img src="https://mm218.dev/posts/2020/04/making-excellent-viz/making-2-1.png" class="img-fluid"></p>
<p>There are all sorts of ways we can do this sort of refactoring – if we wanted, we could get a very similar graph by binning our data and making a bar plot:</p>
<p><img src="https://mm218.dev/posts/2020/04/making-excellent-viz/making-3-1.png" class="img-fluid"></p>
<p>Either way, though, we’re not truly showing the same thing as was in the original graph – we don’t have any indication of the actual distribution of our data set along these axes.</p>
<p>The second solution solves this problem much more effectively – make all your points semi-transparent:</p>
<p><img src="https://mm218.dev/posts/2020/04/making-excellent-viz/making-4-1.png" class="img-fluid"></p>
<p>By doing this, we’re now able to see areas where our data is much more densely distributed, something that was lost in the summary statistics – for instance, it appears that low-carat diamonds are much more tighly grouped than higher carat ones. We can also see some dark stripes at “round-number” values for carat – that indicates to me that our data has some integrity issues, if appraisers are more likely to give a stone a rounded number.</p>
<p>The challenge with this approach comes when we want to map a third variable – let’s use cut – in our graphic. We can try to change the aesthetics of our graph as usual:</p>
<p><img src="https://mm218.dev/posts/2020/04/making-excellent-viz/making-5-1.png" class="img-fluid"></p>
<p>But unfortunately the sheer number of points drowns out most of the variance in color and shape on the graphic. In this case, our best option may be to turn to option number three and facet our plots – that is, to split our one large plot into several small multiples:</p>
<p><img src="https://mm218.dev/posts/2020/04/making-excellent-viz/making-6-1.png" class="img-fluid"></p>
<p>Remember: Ink is cheap. Electrons are even cheaper. Make more than one graph.</p>
<p>By splitting out our data into several smaller graphics, we’re much better able to see how the distribution shifts between our categories. In fact, we could use this technique to split our data even further, into a matrix of scatter plots showing how different groups are distributed:</p>
<p><img src="https://mm218.dev/posts/2020/04/making-excellent-viz/making-7-1.png" class="img-fluid"></p>
<p>One last, extremely helpful use of faceting is to split apart charts with multiple entangled lines: <img src="https://mm218.dev/posts/2020/04/making-excellent-viz/making-8-1.png" class="img-fluid"></p>
<p>These charts, commonly referred to as “spaghetti charts”, are usually much easier to use when split into small multiples:</p>
<p><img src="https://mm218.dev/posts/2020/04/making-excellent-viz/making-9-1.png" class="img-fluid"></p>
<p>Now, one major drawback of facet charts is that they can make comparisons much harder – if, in our line chart, it’s more important to know that most clarities are similar in price at 2 carats than it is to know how the price for each clarity changes with carat, then the first chart is likely the more effective option. In those cases, however, it’s worth reassessing how many lines you actually need on your graph – if you only care about a few clarities, then only include those lines, and if you only care about a narrow band of prices or carats, window your data so that’s all you show. The goal is to make making comparisons easy, with the understanding that some comparisons are more important than others.</p>
</section>
<section id="dealing-with-chartjunk" class="level3">
<h3 class="anchored" data-anchor-id="dealing-with-chartjunk">Dealing with chartjunk</h3>
<p>Cast your mind back to the graphic I used as an example of an explanatory chart:</p>
<p><img src="https://mm218.dev/posts/2020/04/making-excellent-viz/making-10-1.png" class="img-fluid"></p>
<p>You might have noticed that this chart is differently styled from all the others in this course – it doesn’t have the grey background or grid lines or anything else.</p>
<p>Think back to our second mantra: everything should be made as simple as possible, but no simpler. This chart reflects that goal. We’ve lost some of the distracting elements – the colored background and grid lines – and changed the other elements to make the overall graphic more effective. The objective is to have no extraneous element on the graph, so that it might be as expressive and effective as possible. This usually means using minimal colors, minimal text, and no grid lines. (After all, those lines are usually only useful in order to pick out a specific value – and if you’re expecting people to need specific values, you should give them a table!)</p>
<p>Those extraneous elements are known as <em>chartjunk</em>. You see this a lot with graphs made in Excel – they’ll have dark backgrounds, dark lines, special shading effects or gradients that don’t encode information, or – worst of all – those “3D” bar/line/pie charts, because these things can be added with a single click. However, they tend to make your graphics less effective as they force the user to spend more time separating data from ornamentation. Everything should be made as simple as possible, but no simpler; every element of your graphic should increase expressiveness or effectiveness. In short: don’t try to pretty up your graph with non-useful elements.</p>
<p>Another common instance of chartjunk is animation in graphics. While animated graphics are exciting and trendy, they tend to reduce the effectiveness of your graphics because as humans, when something is moving we can’t focus on anything else. <a href="http://visionlab.harvard.edu/silencing/">Check out these examples from the Harvard Vision Lab</a> – they show just how hard it is to notice changes when animation is added. This isn’t to say you can never use animation – but its uses are best kept to times when your graphic looking cool is more important than it conveying information.</p>
</section>
<section id="common-mistakes" class="level3">
<h3 class="anchored" data-anchor-id="common-mistakes">Common Mistakes</h3>
<p>As we wind down this section, I want to touch on a few common mistakes that didn’t have a great home in any other section – mostly because we were too busy talking about <em>good</em> design principles.</p>
</section>
<section id="dual-y-axes" class="level3">
<h3 class="anchored" data-anchor-id="dual-y-axes">Dual y axes</h3>
<p>Chief amongst these mistakes are plots with two y axes, beloved by charlatans and financial advisors since days unwritten. Plots with two y axes are a great way to force a correlation that doesn’t really exist into existence on your chart, through manipulation of your units and axes. In almost every case, you should just make two graphs – ink is cheap. Electrons are even cheaper.</p>
<p>For an extremely entertaining read on this subject, <a href="https://kieranhealy.org/blog/archives/2016/01/16/two-y-axes/">check out this link</a>. I’ve borrowed Kieran’s code for the below viz – look at how we can imply different things, just by changing how we scale our axes!</p>
<p><img src="https://mm218.dev/posts/2020/04/making-excellent-viz/making-11-1.png" class="img-fluid"></p>
</section>
<section id="overcomplex-visualizations" class="level3">
<h3 class="anchored" data-anchor-id="overcomplex-visualizations">Overcomplex visualizations</h3>
<p>Another common issue in visualizations comes from the analyst getting a little too technical with their graphs. For instance, think back to our original diamonds scatter plot: <img src="https://mm218.dev/posts/2020/04/making-excellent-viz/making-12-1.png" class="img-fluid"></p>
<p>Looking at this chart, we can see that carat and price have a positive correlation – as one increases, the other does as well. However, it’s not a linear relationship; instead, it appears that price increases faster as carat increases.</p>
<p>The more statistically-minded analyst might already be thinking that we could make this relationship linear by log-transforming the axes – and they’d be right! We can see a clear linear relationship when we make the transformation:</p>
<p><img src="https://mm218.dev/posts/2020/04/making-excellent-viz/making-13-1.png" class="img-fluid"></p>
<p>Unfortunately, transforming your visualizations in this way can make your graphic hard to understand – in fact, only about <a href="https://www.nature.com/articles/s41559-018-0610-7?WT.feed_name=subjects_ecology">60% of professional scientists</a> can even understand them. As such, transforming your axes like this tends to reduce the effectiveness of your graphic – this type of visualization should be reserved for exploratory graphics and modeling, instead.</p>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion</h3>
<p>And that just about wraps up this introduction to the basic concepts of data visualizations. Hopefully you’ve picked up some concepts or vocabulary that can help you think about your own visualizations in your daily life. I wanted to close out here with a list of resources I’ve found helpful in making graphics – I’ll keep adding to this over time:</p>
<ul>
<li>When picking colors, I often find myself reaching for one of the following tools:
<ul>
<li><a href="http://colorbrewer2.org/#type=diverging&amp;scheme=BrBG&amp;n=5">ColorBrewer</a> provided most of the palettes for these graphics</li>
<li><a href="https://colorsupplyyy.com/">ColorSupply</a> makes picking custom colors easier</li>
<li><a href="https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html">Viridis</a> provides beautiful, colorblind-friendly palettes for use (though this resource is a little harder to understand)</li>
</ul></li>
<li>I used the following resources in putting this post together:
<ul>
<li><a href="http://stat405.had.co.nz/">Hadley Wickham’s Stat 405 Course</a>, particularly the lecture on <a href="http://stat405.had.co.nz/lectures/20-effective-vis.pdf">effective visualizations</a> (I’ve lifted “perceptual topology should match data toplogy”, “make important comparisons easy”, and “visualization is only one part of data analysis” directly from his slides)</li>
<li><a href="https://courses.cs.washington.edu/courses/cse442/17au/lectures/CSE442-VisualEncoding.pdf">Jeffrey Heer’s CSE 442 lecture on visualizations</a>, particularly the definitions for expressiveness and effectiveness</li>
</ul></li>
</ul>
<hr>


</section>

 ]]></description>
  <category>Data Visualization</category>
  <category>Tutorials</category>
  <guid>https://mm218.dev/posts/2020/04/making-excellent-viz/index.html</guid>
  <pubDate>Wed, 22 Apr 2020 04:00:00 GMT</pubDate>
  <media:content url="https://mm218.dev/posts/2020/04/making-excellent-viz/making-1-1.png" medium="image" type="image/png" height="103" width="144"/>
</item>
<item>
  <title>Mechanics of Data Visualizations</title>
  <dc:creator>Mike Mahoney</dc:creator>
  <link>https://mm218.dev/posts/2020/04/mechanics-of-viz/index.html</link>
  <description><![CDATA[ 




<p><em>(Note: this is part two of a three part series on data visualization,</em> <em>originally published on <a href="https://towardsdatascience.com/the-art-and-science-of-data-visualization-6f9d706d673e">Towards Data Science in 2019</a>.</em></p>
<p>Let’s move from theoretical considerations of graphing to the actual building blocks you have at your disposal. As we do so, we’re also going to move on to mantra #2:</p>
<section id="everything-should-be-made-as-simple-as-possible-but-no-simpler." class="level3">
<h3 class="anchored" data-anchor-id="everything-should-be-made-as-simple-as-possible-but-no-simpler.">Everything should be made as simple as possible – but no simpler.</h3>
<p>Graphs are inherently a 2D image of our data:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-1-1.png" class="img-fluid"></p>
<p>They have an x and a y scale, and - as in our scatter plot here - the position a point falls along each scale tells you how large its values are. But this setup only allows us to look at two variables in our data - and we’re frequently interested in seeing relationships between more than two variables.</p>
<p>So the question becomes: how can we visualize those extra variables? We can try adding another position scale:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1">knitr<span class="sc" style="color: #5E5E5E;">::</span><span class="fu" style="color: #4758AB;">include_graphics</span>(<span class="st" style="color: #20794D;">"unnamed-chunk-2-1.png"</span>)</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-2-1.png" class="img-fluid" style="width:100.0%"></p>
</div>
</div>
<p>But 3D images are hard to wrap your head around, complicated to produce, and not as effective in delivering your message. They do have their uses - particularly when you’re able to build real, physical 3D models, and not just make 3D shapes on 2D planes - but frequently aren’t worth the trouble.</p>
<p>So what tools do we have in our toolbox? The ones that are generally agreed upon (no, really - this is an area of active debate) fall into four categories:</p>
<ul>
<li>Position (like we already have with X and Y)</li>
<li>Color</li>
<li>Shape</li>
<li>Size</li>
</ul>
<p>These are the tools we can use to encode more information into our graphics. We’re going to call these <em>aesthetics</em>, but any number of other words could work - some people refer to them as scales, some as values. I call them aesthetics because that’s what my software of choice calls them - but the word itself comes from the fact that these are the things that change how your graph looks.</p>
<p>For what it’s worth, we’re using an EPA data set for this unit, representing fuel economy data from 1999 and 2008 for 38 popular models of car. “Hwy” is highway mileage, “displ” is engine displacement (so volume), and “cty” is city mileage. But frankly, our data set doesn’t matter right now - most of our discussion here is applicable to any data set you’ll pick up.</p>
<p>We’re going to go through each of these aesthetics, to talk about how you can encode more information in each of your graphics. Along the way, remember our mantras:</p>
<ol type="1">
<li>A good graphic tells a story</li>
<li>Everything should be made as simple as possible - but no simpler</li>
<li>Use the right tool for the job</li>
<li>Ink is cheap. Electrons are even cheaper</li>
</ol>
<p>We’ll talk about how these are applicable throughout this section.</p>
</section>
<section id="position" class="level3">
<h3 class="anchored" data-anchor-id="position">Position</h3>
<p>Let’s start off discussing these aesthetics by finishing up talking about position. The distance of values along the x, y, or – in the case of our 3D graphic – z axes represents how large a particular variable is. People inherently understand that values further out on each axis are more extreme - for instance, imagine you came across the following graphic (made with simulated data):</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-3-1.png" class="img-fluid"></p>
<p>Which values do you think are higher?</p>
<p>Most people innately assume that the bottom-left hand corner represents a 0 on both axes, and that the further you get from that corner the higher the values are. This – relatively obvious – revelation hints at a much more important concept in data visualizations: perceptual topology should match data topology. Put another way, that means that values which <em>feel</em> larger in a graph should represent values that <em>are</em> larger in your data. As such, when working with position, higher values should be the ones further away from that lower left-hand corner – you should let your viewer’s subconscious assumptions do the heavy lifting for you.</p>
<p>Applying this advice to categorical data can get a little tricky. Imagine that we’re looking at the average highway mileages for manufacturers of the cars in our data set:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-4-1.png" class="img-fluid"></p>
<p>In this case, the position along the x axis just represents a different car maker, in alphabetical order. But remember, position in a graph is an aesthetic that we can use to encode more information in our graphics. And we aren’t doing that here – for instance, we could show the same information without using x position at all:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-5-1.png" class="img-fluid"></p>
<p>Try to compare Pontiac and Hyundai on the first graph, versus on this second one. If anything, removing our extraneous x aesthetic has made it easier to compare manufacturers. This is a big driver behind our second mantra – that everything should be made as simple as possible, but no simpler. Having extra aesthetics confuses a graph, making it harder to understand the story it’s trying to tell.</p>
<p>However, when making a graphic, we should always be aiming to make important comparisons easy. As such, we should take advantage of our x aesthetic by arranging our manufacturers not alphabetically, but rather by their average highway mileage: <img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-6-1.png" class="img-fluid"></p>
<p>By reordering our graphic, we’re now able to better compare more similar manufacturers. It’s now dramatically faster to understand our visualization – closer comparisons are easier to make, so placing more similar values closer together makes them dramatically easier to grasp. Look at Pontiac vs Hyundai now, for instance. Generally speaking, don’t put things in alphabetical order - use the order you place things to encode additional information.</p>
<p>As a quick sidenote, I personally believe that, when working with categorical values along the X axis, you should reorder your values so the highest value comes first. For some reason, I just find having the tallest bar/highest point (or whatever is being used to show value) next to the Y axis line is much cleaner looking than the alternative:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-7-1.png" class="img-fluid"></p>
<p>For what it’s worth, I’m somewhat less dogmatic about this when the values are on the Y axis. I personally believe the highest value should always be at the top, as humans expect higher values to be further from that bottom left corner: <img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-8-1.png" class="img-fluid"></p>
<p>However, I’m not as instantly repulsed by the opposite ordering as I am with the X axis, likely because the bottom bar/point being the furthest looks like a more natural shape, and is still along the X axis line: <img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-9-1.png" class="img-fluid"></p>
<p>For this, at least, your mileage may vary. Also, it’s worth pointing out how much cleaner the labels on this graph are when they’re on the Y axis - flipping your coordinate system, like we’ve done here, is a good way to display data when you’ve got an unwieldy number of categories.</p>
</section>
<section id="color" class="level3">
<h3 class="anchored" data-anchor-id="color">Color</h3>
<p>While we’ve done a good job covering the role position plays in communicating information, we’re still stuck on the same question we started off with: How can we show a third variable on the graph?</p>
<p>One of the most popular ways is to use colors to represent your third variable. It might be worth talking through how color can be used with a simulated data set. Take for example the following graph: <img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-10-1.png" class="img-fluid"></p>
<p>And now let’s add color for our third variable: <img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-11-1.png" class="img-fluid"></p>
<p>Remember: perceptual topology should match data topology. Which values are larger?</p>
<p>Most people would say the darker ones. But is it always that simple? Let’s change our color scale to compare: <img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-12-1.png" class="img-fluid"></p>
<p>Sure, some of these colors are darker than others – but I wouldn’t say any of them tell me a value is particularly high or low.</p>
<p>That’s because humans don’t percieve <em>hue</em> – the actual shade of a color – as an ordered value. The color a point is doesn’t communicate that the point has a higher or lower value than any other point on the graph. Instead, hue works as an <em>unordered</em> value, which only tells us which points belong to which groupings. In order to tell how high or low a point’s value is, we instead have to use <em>luminescence</em> – or how bright or dark the individual point is.</p>
<p>There’s one other axis you can move colors along in order to encode value – how vibrant a color is, known as <em>chroma</em>:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-13-1.png" class="img-fluid"></p>
<p>Just keep in mind that <em>luminescence</em> and <em>chroma</em> – how light a color is and how vibrant it is – are <em>ordered values</em>, while <em>hue</em> (or shade of color) is <em>unordered</em> This becomes relevant when dealing with categorical data. For instance, moving back to the scatter plot we started with:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-14-1.png" class="img-fluid"></p>
<p>If we wanted to encode a categorical variable in this – for instance, the class of vehicle – we could use hue to distinguish the different types of cars from one another:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-15-1.png" class="img-fluid"></p>
<p>In this case, using hue to distinguish our variables clearly makes more sense than using either chroma or luminesence:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-16-1.png" class="img-fluid"></p>
<p>This is a case of knowing what tool to use for the job - chroma and luminescence will clearly imply certain variables are closer together than is appropriate for categorical data, while hue won’t give your audience any helpful information about an ordered variable. Note, though, that I’d still discourage using the rainbow to distinguish categories in your graphics – the colors of the rainbow aren’t exactly unordered values (for instance, red and orange are much more similar colors than yellow and blue), and you’ll wind up implying connections between your categories that you might not want to suggest. Also, the rainbow is just really ugly:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-17-1.png" class="img-fluid"></p>
<p>Speaking of using the right tool for the job, one of the worst things people like to do in data visualizations is overuse color. Take for instance the following example:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-18-1.png" class="img-fluid"></p>
<p>In this graph, the variable “class” is being represented by both position along the x axis, and by color. By duplicating this effort, we’re making our graph harder to understand – encoding the information once is enough, and doing it any more times than that is a distraction. Remember the second mantra: Everything should be made as simple as possible – but no simpler. The best data visualization is one that includes all the elements needed to deliver the message, and no more.</p>
<p>You can feel free to use color in your graphics, so long as it adds more information to the plot - for instance, if it’s encoding a third variable:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-19-1.png" class="img-fluid"></p>
<p>But replicating as we did above is just adding more junk to your chart.</p>
<p>There’s one last way you can use color effectively in your plot, and that’s to highlight points with certain characteristics:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-20-1.png" class="img-fluid"></p>
<p>Doing so allows the viewer to quickly pick out the most important sections of our graph, increasing its effectiveness. Note that I used shape instead of color to separate the class of vehicles, by the way – combining point highlighting and using color to distinguish categorical variables can work, but can also get somewhat chaotic:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-21-1.png" class="img-fluid"></p>
<p>There’s one other reason color is a tricky aesthetic to get right in your graphics: about 5% of the population (10% of men, 1% of women) can’t see colors at all. That means you should be careful when using it in your visualizations – use colorblind-safe color palettes (google “ColorBrewer” or “viridis” for more on these), and pair it with another aesthetic whenever possible.</p>
</section>
<section id="shape" class="level3">
<h3 class="anchored" data-anchor-id="shape">Shape</h3>
<p>The easiest aesthetic to pair color with is the next most frequently used – shape. This one is much more intuitive than color – to demonstrate, let’s go back to our scatter plot:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-22-1.png" class="img-fluid"></p>
<p>We can now change the shape of each point based on what class of vehicle it represents: <img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-23-1.png" class="img-fluid"></p>
<p>Imagine we were doing the same exercise as we did with color earlier – which values are larger?</p>
<p>I’ve spoiled the answer already by telling you what the shapes represent – none of them are inherently larger than the others. Shape, like hue, is an <em>unordered value</em>.</p>
<p>The same basic concepts apply when we change the shape of lines, not just points. For instance, if we plot separate trendlines for front-wheel, rear-wheel, and four-wheel drive cars, we can use linetype to represent each type of vehicle:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-24-1.png" class="img-fluid"></p>
<p>But even here, no one linetype implies a higher or lower value than the others.</p>
<p>There are two caveats to be made to this rule, however. For instance, if we go back to our original scatter plot and change which shapes we’re using:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-25-1.png" class="img-fluid"></p>
<p>This graph seems to imply more connection between the first three classes of car (which are all different types of diamonds) and the next three classes (which are all types of triangle), while singling out SUVs. In this way, we’re able to use shape to imply connection between our groupings - more similar shapes, which differ only in angle or texture, imply a closer relationship to one another than to other types of shape. This can be a blessing as well as a curse - if you pick, for example, a square and a diamond to represent two unrelated groupings, your audience might accidentally read more into the relationship than you had meant to imply.</p>
<p>It’s also worth noting that different shapes can pretty quickly clutter up a graph. As a general rule of thumb, using more than 3-4 shapes on a graph is a bad idea, and more than 6 means you need to do some thinking about what you actually want people to take away.</p>
</section>
<section id="size" class="level3">
<h3 class="anchored" data-anchor-id="size">Size</h3>
<p>Our last aesthetic is that of size. Going back to our original scatter plot, we could imagine using size like this:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-26-1.png" class="img-fluid"></p>
<p>Size is an inherently <em>ordered value</em> - large size points imply larger values. Specifically, humans perceive larger areas as corresponding to larger values - the points which are three times larger in the above graph are about three times larger in value, as well.</p>
<p>This becomes tricky when size is used incorrectly, either by mistake or to distort the data. Sometimes an analyst maps radius to the variable, rather than area of the point, resulting in graphs as the below:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-27-1.png" class="img-fluid"></p>
<p>In this example, the points representing a cty value of 10 don’t look anything close to 1/3 as large as the points representing 30. This makes the increase seem much steeper upon looking at this chart – so be careful when working with size as an aesthetic that your software is using the area of points, not radius!</p>
<p>It’s also worth noting that unlike color – which can be used to distinguish groupings, as well as represent an ordered value – it’s generally a bad idea to use size for a categorical variable. For instance, if we mapped point size to class of vehicle:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-28-1.png" class="img-fluid"></p>
<p>We seem to be implying relationships here that don’t actually exist, like a minivan and midsize vehicle being basically the same. As a result, it’s best to only use size for continuous (or numeric) data.</p>
</section>
<section id="a-tangent" class="level3">
<h3 class="anchored" data-anchor-id="a-tangent">A Tangent</h3>
<p>Now that we’ve gone over these four aesthetics, I want to go on a quick tangent. When it comes to how quickly and easily humans perceive each of these aesthetics, research has settled on the following order:</p>
<ol type="1">
<li>Position</li>
<li>Size</li>
<li>Color (especially chroma and luminescence)</li>
<li>Shape</li>
</ol>
<p>And as we’ve discussed repeatedly, the best data visualization is one that includes exactly as many elements as it takes to deliver a message, and no more. Everything should be made as simple as possible, but no simpler.</p>
<p>However, we live in a world of humans, where the scientifically most effective method is not always the most popular one. And since color is inherently more exciting than size as an aesthetic, the practitioner often finds themselves using colors to denote values where size would have sufficed. And since we know that color should usually be used alongside shape in order to be more inclusive in our visualizations, size often winds up being the last aesthetic used in a chart. This is fine - sometimes we have to optimize for other things than “how quickly can someone understand my chart”, such as “how attractive does my chart look” or “what does my boss want from me”. But it’s worth noting, in case you see contradictory advice in the future - the disagreement comes from if your source is teaching the most scientifically sound theory, or the most applicable practice.</p>
</section>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary</h3>
<p>We started off this section with our second mantra: that everything should be made as simple as possible, but no simpler. The first half of that cautions us against overusing aesthetics and against adding too much to a graphic, lest we erode its efficency in conveying information:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-29-1.png" class="img-fluid"></p>
<p>The second half cautions us against not using all the aesthetics it takes to tell our story, in case we don’t produce the most expressive graphic possible: <img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-30-1.png" class="img-fluid"></p>
<p>Instead, we should use exactly as many aesthetics as it takes to tell our story, carefully choosing each to encode the most information possible into our graphics: <img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-31-1.png" class="img-fluid"></p>
<p>As for the specific takeaways from this section, I can think of the following:</p>
<ul>
<li>Match perceptual and data topology – if a color or position <em>feels like a higher value</em>, use it to represent data that is a higher value</li>
<li>Make important comparisons easy – place them near each other, call attention to them</li>
<li>Use aesthetics to encode more information into your graphics
<ul>
<li>Use exactly as many aesthetics as you need – no more, no less.</li>
</ul></li>
<li>Don’t place things in alphabetical order</li>
<li>Don’t use the rainbow for a color scheme</li>
<li>Use ordered aesthetics (like position, chroma, luminescence, and size) to show ordered values (like numeric data)</li>
<li>Use unordered aesthetics (like hue or shape) to show unordered values</li>
</ul>
<p>Let’s transition away from aesthetics, and towards our third mantra:</p>
</section>
<section id="use-the-right-tool-for-the-job." class="level3">
<h3 class="anchored" data-anchor-id="use-the-right-tool-for-the-job.">Use the right tool for the job.</h3>
<p>Think back to our first chart:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-32-1.png" class="img-fluid"></p>
<p>As you already know, this is a <em>scatter plot</em> - also known as a <em>point graph</em>. Now say we added a line of best fit to it:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-33-1.png" class="img-fluid"></p>
<p>This didn’t stop being a scatter plot once we drew a line on it – but the term scatter plot no longer really encompasses everything that’s going on here. It’s also obviously not a line chart, as even though there’s a line on it, it also has points.</p>
<p>Rather than quibble about what type of chart this is, it’s more helpful to describe what tools we’ve used to depict our data. We refer to these as <em>geoms</em>, short for <em>geometries</em> – because when you get really deep into things, these are geometric representations of how your data set is distributed along the x and y axes of your graph. I don’t want to get too far down that road – I just want to explain the vocabulary so that we aren’t talking about <em>what type of chart</em> that is, but rather <em>what geoms it uses</em>. Framing things that way makes it easier to understand how things can be combined and reformatted, rather than assuming each type of chart can only do one thing.</p>
</section>
<section id="two-continuous-variables" class="level3">
<h3 class="anchored" data-anchor-id="two-continuous-variables">Two continuous variables</h3>
<p>This chart uses two geoms that are really good for graphs that have a continuous y and a continuous x - points and lines. This is what people refer to most of the time when they say a line graph - a single smooth trendline that shows a pattern in the data. However, a line graph can also mean a chart where each point is connected in turn:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-34-1.png" class="img-fluid"></p>
<p>It’s important to be clear about which type of chart you’re expected to produce! I always refer to the prior as a trendline, for clarity.</p>
<p>These types of charts have enormous value for quick exploratory graphics, showing how various combinations of variables interact with one another. For instance, many analysts start familiarizing themselves with new data sets using correlation matrices (also known as scatter plot matrices), which create a grid of scatter plots representing each variable:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-35-1.png" class="img-fluid"></p>
<p>In this format, understanding interactions between your data is quick and easy, with certain variable interactions obviously jumping out as promising avenues for further exploration.</p>
<p>To back up just a little, there’s one major failing of scatter plots that I want to highlight before moving on. If you happen to have more than one point with the same x and y values, a scatter plot will just draw each point over the previous, making it seem like you have less data than you actually do. Adding a little bit of random noise - for instance, using RAND() in Excel - to your values can help show the actual densities of your data, especially when you’re dealing with numbers that haven’t been measured as precisely as they could a have been. <img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-36-1.png" class="img-fluid"></p>
<p>One last chart that does well with two continuous variables is the area chart, which resembles a line chart but fills in the area beneath the line: <img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-37-1.png" class="img-fluid"></p>
<p>Area plots make sense when 0 is a relevant number to your data set – that is, a 0 value wouldn’t be particularly unexpected. They’re also frequently used when you have multiple groupings and care about their total sum:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-38-1.png" class="img-fluid"></p>
<p>(This new data set is the “diamonds” data set, representing 54,000 diamonds sizes, qualities, cut, and sale prices. We’ll be going back and forth using it and the EPA data set from now on.)</p>
<p>Now one drawback of stacked area charts is that it can be very hard to estimate how any individual grouping shifts along the x axis, due to the cumulative effects of all the groups underneath them. For instance, there are actually fewer “fair” diamonds at 0.25 carats than at 1.0 – but because “ideal” and “premium” spike so much, your audience might draw the wrong conclusions. In situations where the total matters more than the groupings, this is alright – but otherwise, it’s worth looking at other types of charts as a result.</p>
</section>
<section id="one-continuous-variable" class="level3">
<h3 class="anchored" data-anchor-id="one-continuous-variable">One continuous variable</h3>
<p>If instead you’re looking to see how a single continuous variable is distributed throughout your data set, one of the best tools at your disposal is the histogram. A histogram shows you how many observations in your data set fall into a certain range of a continuous variable, and plot that count as a bar plot:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-39-1.png" class="img-fluid"></p>
<p>One important flag to raise with histograms is that you need to pay attention to how your data is being binned. If you haven’t picked the right width for your bins, you might risk missing peaks and valleys in your data set, and might misunderstand how your data is distributed – for instance, look what shifts if we graph 500 bins, instead of the 30 we used above: <img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-40-1.png" class="img-fluid"></p>
<p>An alternative to the histogram is the frequency plot, which uses a line chart in the place of bars to represent the frequency of a value in your data set: <img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-41-1.png" class="img-fluid"></p>
<p>Again, however, you have to pay attention to how wide your data bins are with these charts – you might accidentally smooth over major patterns in your data if you aren’t careful! <img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-42-1.png" class="img-fluid"></p>
<p>One large advantage of the frequency chart over the histogram is how it deals with multiple groupings – if your groupings trade dominance at different levels of your variable, the frequency graph will make it much more obvious how they shift than a histogram will.</p>
<p>(Note that I’ve done something weird to the data in order to show how the distributions change below.) <img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-43-1.png" class="img-fluid"></p>
</section>
<section id="one-categorical-variable-one-continuous" class="level3">
<h3 class="anchored" data-anchor-id="one-categorical-variable-one-continuous">One categorical variable, one continuous</h3>
<p>If you want to compare a categorical and continuous variable, you’re usually stuck with some form of bar chart:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-44-1.png" class="img-fluid"></p>
<p>The bar chart is possibly the least exciting type of graph in existence, mostly because of how prevalent it is – but that’s because it’s really good at what it does. Bar charts are one of the most easily interpreted and effective types of visualizations, no matter how exciting they are.</p>
<p>However, some people are really intent on ruining that. Take, for instance, the stacked bar chart, often used to add a third variable to the mix:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-45-1.png" class="img-fluid"></p>
<p>Compare Fair/G to Premium/G. It’s next to impossible to accurately compare the boxes – they don’t share a top or a bottom line, so you can’t really make a comparison. In these situations, it’s a better idea to use a dodged bar chart instead:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-46-1.png" class="img-fluid"></p>
<p>Dodged bar charts are usually a better choice for comparing the actual numbers of different groupings. However, this chart does a good job showing one of the limitations dodged bar charts come up against – once you get past 4 or 5 groupings, making comparisons is tricky. In these cases, you’re probably trying to apply the wrong chart for the job, and should consider either breaking your chart up into smaller ones – remember, ink is cheap, and electrons or cheaper – or replacing your bars with a few lines.</p>
<p>The one place where stacked bar charts are appropriate, however, is when you’re comparing the relative proportions of two different groups in each bar. For instance, take the following graph:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-47-1.png" class="img-fluid"></p>
<p>In this case, making comparisons across groups is trivial, made simple by the fact that the groupings all share a common line - at 100% for group 1, and at 0% for group 2. This point of reference solves the issue we had with more than two groupings – though note we’d still prefer a dodged bar chart if the bars didn’t always sum to the same amount.</p>
<section id="a-quick-tangent" class="level4">
<h4 class="anchored" data-anchor-id="a-quick-tangent">A Quick Tangent</h4>
<p>This is usually where most people will go on a super long rant about pie charts and how bad they are. They’re wrong, but in an understandable way.</p>
<p>People love to hate on pie charts, because they’re almost universally a bad chart. However, if it’s important for your viewer to be able to quickly figure out what proportion two or more groupings make up of the whole, a pie chart is actually the fastest and most effective way to get the point across. For instance, compare the following pie and bar charts, made with the same data set: <img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-48-1.png" class="img-fluid"></p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-49-1.png" class="img-fluid"></p>
<p>It’s a lot easier to tell that, say, A is smaller than C through F in the pie chart than the bar plot, since humans are better at summing angles than areas. In these instances, feel free to use a pie chart – and to tell anyone giving you flack that I said it was OK.</p>
</section>
</section>
<section id="two-categorical-variables" class="level3">
<h3 class="anchored" data-anchor-id="two-categorical-variables">Two categorical variables</h3>
<p>Our last combination is when you’re looking to have a categorical variable on both the x and y axis. These are trickier plots to think about, as we no longer encode value in position based on how far away a point is from the lower left hand corner, but rather have to get creative in effectively using position to encode a value. Remember that a geom is a geometric representation of how your data set is distributed along the x and y axes of your graph. When both of your axes are categorical, you have to get creative to show that distribution.</p>
<p>One method is to use density, as we would in a scatter plot, to show how many datapoints you have falling into each combination of categories graphed. You can do this by making a “point cloud” chart, where more dense clouds represent more common combinations: <img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-50-1.png" class="img-fluid"></p>
<p>Even without a single number on this chart, its message is clear - we can tell how our diamonds are distributed with a single glance. A similar way to do this is to use a heatmap, where differently colored cells represent a range of values:</p>
<p><img src="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-51-1.png" class="img-fluid"></p>
<p>I personally think heatmaps are less effective – partially because by using the color aesthetic to encode this value, you can’t use it for anything else – but they’re often easier to make with the resources at hand.</p>


</section>

 ]]></description>
  <category>Data Visualization</category>
  <category>Tutorials</category>
  <guid>https://mm218.dev/posts/2020/04/mechanics-of-viz/index.html</guid>
  <pubDate>Tue, 21 Apr 2020 04:00:00 GMT</pubDate>
  <media:content url="https://mm218.dev/posts/2020/04/mechanics-of-viz/unnamed-chunk-1-1.png" medium="image" type="image/png" height="103" width="144"/>
</item>
<item>
  <title>Theory of Data Visualizations</title>
  <dc:creator>Mike Mahoney</dc:creator>
  <link>https://mm218.dev/posts/2020/04/theory-of-data-viz/index.html</link>
  <description><![CDATA[ 




<p><em>(Note: this is part one of a three part series on data visualization,</em> <em>originally published on <a href="https://towardsdatascience.com/the-art-and-science-of-data-visualization-6f9d706d673e">Towards Data Science in 2019</a>.</em></p>
<p>Data visualization – our working definition will be “the graphical display of data” – is one of those things like driving, cooking, or being funny: everyone thinks they’re really great at it, because they’ve been doing it for a while, and yet many – if not most – people don’t even know where they could start learning how much better they could be doing things. For something so essential to so many people’s daily work, data visualization is so rarely directly taught, and is usually assumed to be something people will pick up with time.</p>
<p>However, that isn’t the best approach. Data visualization is a skill like any other, and even experienced practitioners could benefit from honing their skills in the subject. Hence, this series.</p>
<p>This series doesn’t set out to teach you how to make a specific graphic in a specific software. I don’t know what softwares might be applicable to your needs in the future, or what visualizations you’ll need to formulate when, and quite frankly Google exists – so this isn’t a cookbook with step-by-step instructions. The goal here is not to provide you with recipes for the future, but rather to teach you what flour is – to introduce you to the basic concepts and building blocks of effective data visualizations.</p>
<section id="the-mantras" class="level3">
<h3 class="anchored" data-anchor-id="the-mantras">The mantras</h3>
<p>As much as possible, I’ve collapsed those concepts into four mantras we’ll return to throughout this course. The mantras are:</p>
<ol type="1">
<li>A good graphic tells a story.</li>
<li>Everything should be made as simple as possible, but no simpler.</li>
<li>Use the right tool for the job.</li>
<li>Ink is cheap. Electrons are even cheaper.</li>
</ol>
<p>Each mantra serves as the theme for a section, and will also be interwoven throughout. The theme of this section is, easily enough:</p>
</section>
<section id="a-good-graphic-tells-a-story" class="level3">
<h3 class="anchored" data-anchor-id="a-good-graphic-tells-a-story">A good graphic tells a story</h3>
<p>When making a graphic, it is important to understand what the graphic is for. After all, you usually won’t make a chart that is an exact depiction of your data – modern data sets tend to be too big (in terms of number of observations) and wide (in terms of number of variables) to depict every datapoint on a single graph. Instead, the analyst consciously chooses what elements to include in a visualization in order to identify patterns and trends in the data in the most effective manner possible. In order to make those decisions, it helps a little to think both about <em>why</em> and <em>how</em> graphics are made.</p>
</section>
<section id="why-do-we-tell-a-story" class="level3">
<h3 class="anchored" data-anchor-id="why-do-we-tell-a-story">Why do we tell a story?</h3>
<p>As far as the <em>why</em> question goes, the answer usually comes down to one of two larger categories:</p>
<ul>
<li>To help identify patterns in a data set, or</li>
<li>To explain those patterns to a wider audience</li>
</ul>
<p>These are the rationales behind creating what are known as, respectively, <em>exploratory</em> and <em>explanatory</em> graphics. Exploratory graphics are often very simple pictures of your data, built to identify patterns in your data that you might not know exist yet. Take for example a simple graphic, showing tree circumference as a function of age:</p>
<p><img src="https://mm218.dev/posts/2020/04/theory-of-data-viz/theory1.png" class="img-fluid"></p>
<p>This visualization isn’t anything too complex – two variables, thirty-five observations, not much text – but it already shows us a trend that exists in the data. We could use this information, if we were so inspired, to start investigating the <em>whys</em> of why tree growth changes with age, now that we’re broadly aware of <em>how</em> it changes.</p>
<p>Explanatory graphs, meanwhile, are all about the <em>whys</em>. Where an exploratory graphic focuses on identifying patterns in the first place, an explanatory graphic aims to explain why they happen and – in the best examples – what exactly the reader is to do about them. Explanatory graphics can exist on their own or in the context of a larger report, but their goals are the same: to provide evidence about why a pattern exists and provide a call to action. For instance, we can reimagine the same tree graph with a few edits in order to explain what patterns we’re seeing:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1">knitr<span class="sc" style="color: #5E5E5E;">::</span><span class="fu" style="color: #4758AB;">include_graphics</span>(<span class="st" style="color: #20794D;">"theory2.png"</span>)</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://mm218.dev/posts/2020/04/theory-of-data-viz/theory2.png" class="img-fluid" style="width:100.0%"></p>
</div>
</div>
<p>I want to specifically call out the title here: “Orange tree growth tapers by year 4.” A good graphic tells a story, remember. As such, whatever title you give your graph should reflect the point of that story – titles such as “Tree diameter (cm) versus age (days)” and so on add nothing that the user can’t get from the graphic itself. Instead, use your title to advance your message whenever it makes sense – otherwise, if it doesn’t add any new information, you’re better off erasing it altogether.</p>
<p>The important takeaway here is not that explanatory graphics are necessarily more polished than exploratory ones, or that exploratory graphics are only for the analyst – periodic reporting, for instance, will often use highly polished exploratory graphics to identify existing trends, hoping to spur more intensive analysis that will identify the whys. Instead, the message is that knowing the end purpose of your graph – whether it should help identify patterns in the first place or explain how they got there – can help you decide what elements need to be included to tell the story your graphic is designed to address.</p>
</section>
<section id="how-do-we-tell-a-story" class="level3">
<h3 class="anchored" data-anchor-id="how-do-we-tell-a-story">How do we tell a story?</h3>
<p>The other important consideration when thinking about graph design is the actual <em>how</em> you’ll tell your story, including what design elements you’ll use and what data you’ll display. My preferred paradigm when deciding between the possible “hows” is to weigh the <em>expressiveness and effectiveness</em> of the resulting graphic – as defined by Jeffrey Heer at the University of Washington, that means:</p>
<ul>
<li><strong>Expressiveness</strong>: A set of facts is expressible in a visual language if the sentences (i.e.&nbsp;the visualizations) in the language express all the facts in the set of data, and only the facts in the data.<br>
</li>
<li><strong>Effectiveness</strong>: A visualization is more effective than another visualization if the information conveyed by one visualization is more readily perceived than the information in the other visualization.</li>
</ul>
<p>Or, to simplify:</p>
<ol type="1">
<li>Tell the truth and nothing but the truth (don’t lie, and don’t lie by omission)</li>
<li>Use encodings that people decode better (where better = faster and/or more accurate)</li>
</ol>
<p>Keep this concept in the back of your mind as we move into the mechanics of data visualization in our next post – it should be your main consideration while deciding which elements you use! We’ll keep returning to these ideas of explanatory and exploratory, as well as expressiveness and effectiveness, throughout the rest of this article.</p>


</section>

 ]]></description>
  <category>Data Visualization</category>
  <category>Tutorials</category>
  <guid>https://mm218.dev/posts/2020/04/theory-of-data-viz/index.html</guid>
  <pubDate>Mon, 20 Apr 2020 04:00:00 GMT</pubDate>
  <media:content url="https://mm218.dev/posts/2020/04/theory-of-data-viz/theory1.png" medium="image" type="image/png" height="103" width="144"/>
</item>
<item>
  <title>Announcing {spacey}, now on CRAN!</title>
  <dc:creator>Mike Mahoney</dc:creator>
  <link>https://mm218.dev/posts/2020/03/index.html</link>
  <description><![CDATA[ 




<p>I’ve launched a new package to CRAN! <code>spacey</code> helps you pull elevation and image overlay data from the USGS and ESRI, then helps you turn them into beautiful maps via <a href="https://www.rayshader.com/">the fantastic <code>rayshader</code> package</a>.</p>
<p>The package has a <a href="https://mikemahoney218.github.io/spacey/">documentation website</a> built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> – check it out for more information!</p>



 ]]></description>
  <category>R</category>
  <category>R Packages</category>
  <category>maps</category>
  <category>spacey</category>
  <category>geospatial data</category>
  <guid>https://mm218.dev/posts/2020/03/index.html</guid>
  <pubDate>Tue, 24 Mar 2020 04:00:00 GMT</pubDate>
</item>
<item>
  <title>Announcing {heddlr}, now on CRAN!</title>
  <dc:creator>Mike Mahoney</dc:creator>
  <link>https://mm218.dev/posts/2020/01/index.html</link>
  <description><![CDATA[ 




<p>My first package just got published to CRAN today! <code>heddlr</code> is a set of tools that make it easier to write modular R Markdown documents by decomposing them into a set of patterns which can be repeated and combined based on your input data, letting you dynamically add and remove sections based on your data. I started this package to solve an issue I found myself running into when building <a href="https://rmarkdown.rstudio.com/flexdashboard/">flexdashboards</a>, and have since found out that there’s all sorts of cool tricks you can do by applying this type of functional programming mindset to R Markdown documents.</p>
<p>You can find out more on heddlr’s <a href="https://mikemahoney218.github.io/heddlr/">documentation website</a>, proudly made in R via <a href="https://pkgdown.r-lib.org/">pkgdown</a>. This first version on CRAN is 0.5.0, with 0.1 -&gt; 0.4 previously released on <a href="https://github.com/mikemahoney218/heddlr">GitHub</a>.</p>



 ]]></description>
  <category>R</category>
  <category>R Packages</category>
  <category>R Markdown</category>
  <guid>https://mm218.dev/posts/2020/01/index.html</guid>
  <pubDate>Thu, 23 Jan 2020 05:00:00 GMT</pubDate>
</item>
<item>
  <title>Thesis Now Available in ESF Digital Commons</title>
  <dc:creator>Mike Mahoney</dc:creator>
  <link>https://mm218.dev/posts/2019/03/index.html</link>
  <description><![CDATA[ 




<p>My thesis is now available on the <a href="https://digitalcommons.esf.edu/honors/141/">ESF Digital Commons</a>! I’m extremely grateful to Drs. John Drake and Bill Shields for their help in the revision and submission process, and of course to Dr.&nbsp;John Stella for the extensive support he provided throughout the project, from conceptualization to publication.</p>
<p>In the thesis, we look at the impacts beavers have on the forest community around them as they remove trees for food and building dams. While people had looked at these impacts in other parts of beaver’s range, the Adirondacks are a strange enough ecosystem - being largely protected from anthropogenic disturbances, most of the forest landscape exhibits only one or two age classes - that we weren’t sure how applicable conclusions from these regions would be. What we found was that while the broad conclusions of these studies held true - beavers still operate as central place foragers and create large disturbances in the landscape - the lack of early-successional species throughout the Adirondacks seriously shifted which stems were harvested preferrentially. We also found a lot of variance in the patterns of how individual species were utilized - for instance, beaver harvested almost any size speckled alder they could find, so long as it was close to their dam, but would harvest red maple at any distance, so long as the stem was small.</p>
<p><img src="https://mm218.dev/posts/2019/03/Wireframes.png" class="img-fluid"></p>
<p>We’re currently working on a journal article version of the thesis, using an expanded dataset and focusing more closely on the patterns in forage selectivity we found, and how they differ from other regions. That should hopefully be in the review process within the next few weeks.</p>



 ]]></description>
  <category>Publications</category>
  <category>Beaver</category>
  <guid>https://mm218.dev/posts/2019/03/index.html</guid>
  <pubDate>Wed, 27 Mar 2019 04:00:00 GMT</pubDate>
  <media:content url="https://mm218.dev/posts/2019/03/Wireframes.png" medium="image" type="image/png" height="157" width="144"/>
</item>
</channel>
</rss>
